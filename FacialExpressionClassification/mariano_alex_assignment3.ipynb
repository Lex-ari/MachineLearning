{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0A_JriDGhBkF"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT7ME9FqVIg_",
        "outputId": "736e8ec6-e47c-4003-f8af-c2aa8f366029"
      },
      "outputs": [],
      "source": [
        "# Module imports\n",
        "from __future__ import print_function\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils import shuffle\n",
        "%matplotlib inline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset\n",
        "import cv2\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ZQ50JDWGVpWt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 16174 entries, 0 to 16173\n",
            "Columns: 2304 entries, 146 to 81.32\n",
            "dtypes: int64(2304)\n",
            "memory usage: 284.3 MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 16174 entries, 0 to 16173\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype\n",
            "---  ------  --------------  -----\n",
            " 0   1       16174 non-null  int64\n",
            "dtypes: int64(1)\n",
            "memory usage: 126.5 KB\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>16174.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.059973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.741898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  1\n",
              "count  16174.000000\n",
              "mean       1.059973\n",
              "std        0.741898\n",
              "min        0.000000\n",
              "25%        1.000000\n",
              "50%        1.000000\n",
              "75%        2.000000\n",
              "max        2.000000"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rawdata = pd.read_csv('train_data.csv')\n",
        "# display the top rows\n",
        "rawdata.head(10)\n",
        "# get a quick description of the data, including # of rows, # of features, name of each feature, type of each feature, # of non-null values\n",
        "rawdata.info()\n",
        "# show a summary of the numerical attributes\n",
        "rawdata.describe()\n",
        "\n",
        "rawtargetdata = pd.read_csv('train_target.csv')\n",
        "# display the top rows\n",
        "rawtargetdata.head(10)\n",
        "# get a quick description of the data, including # of rows, # of features, name of each feature, type of each feature, # of non-null values\n",
        "rawtargetdata.info()\n",
        "# show a summary of the numerical attributes\n",
        "rawtargetdata.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vG3znnVYh3Fo"
      },
      "source": [
        "#  Task 1: Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Ylr3j8GD_Eoq"
      },
      "outputs": [],
      "source": [
        "# num_pipeline = Pipeline([\n",
        "#     ('std_scaler', StandardScaler()),\n",
        "# ])\n",
        "\n",
        "# data_preprocessed = num_pipeline.fit_transform(rawdata)\n",
        "data_preprocessed = rawdata.to_numpy()\n",
        "targets_preprocessed = rawtargetdata.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qey-gjetiXTI"
      },
      "source": [
        "# Task 2: Split Dataset for Training, Validation, and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_data.shape: (12939, 2304)\n",
            "train_target.shape: (12939, 1)\n",
            "\n",
            "valid_data.shape: (3235, 2304)\n",
            "valid_target.shape: (3235, 1)\n"
          ]
        }
      ],
      "source": [
        "train_data, valid_data, train_target, valid_target = train_test_split(data_preprocessed, targets_preprocessed, test_size = 0.20, random_state = 42)\n",
        "\n",
        "#print(train_data)\n",
        "print(f\"train_data.shape: {train_data.shape}\")\n",
        "print(f\"train_target.shape: {train_target.shape}\")\n",
        "print()\n",
        "print(f\"valid_data.shape: {valid_data.shape}\")\n",
        "print(f\"valid_target.shape: {valid_target.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, train_data, train_target, transform = None, target_transform = None):\n",
        "        super().__init__()\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.data = []\n",
        "        self.targets = []\n",
        "        \n",
        "        for image in train_data:\n",
        "            reshaped_array = np.reshape(image, (48, 48))\n",
        "            pil_image = Image.fromarray(np.uint8(reshaped_array))\n",
        "            self.data.append(pil_image)\n",
        "            rotate_pos_10 = pil_image.rotate(20)\n",
        "            self.data.append(rotate_pos_10)\n",
        "            rotate_neg_10 = pil_image.rotate(-20)\n",
        "            self.data.append(rotate_neg_10)\n",
        "            flipped = pil_image.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "            self.data.append(flipped)\n",
        "        for target in train_target:\n",
        "            self.targets.append(target[0])\n",
        "            self.targets.append(target[0])\n",
        "            self.targets.append(target[0])\n",
        "            self.targets.append(target[0])\n",
        "        #self.data = np.vstack(self.data).reshape(-1, 48, 48)\n",
        "        #self.data = self.data.transpose((0, 1, 2))  # convert to Hight by Width by Channel\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        img, target = self.data[idx], self.targets[idx]\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainingDataset = CustomDataset(train_data, train_target,\n",
        "    transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.4915, 0.2470)\n",
        "    ]))\n",
        "validationDataset = CustomDataset(valid_data, valid_target,\n",
        "    transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.4915, 0.2470)\n",
        "    ]))\n",
        "\n",
        "# print(trainingDataset.data[0])\n",
        "\n",
        "# image, target = trainingDataset.__getitem__(0)\n",
        "# plt.imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "kwargs = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available()else {}\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(trainingDataset, batch_size=64, shuffle=True,  **kwargs)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(validationDataset, batch_size=64,shuffle=False, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_out = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
              "  (1): ReLU()\n",
              "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (3): Dropout2d(p=0.4, inplace=False)\n",
              "  (4): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
              "  (5): ReLU()\n",
              "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (7): Dropout2d(p=0.4, inplace=False)\n",
              "  (8): ReLU()\n",
              "  (9): Dropout2d(p=0.4, inplace=False)\n",
              "  (10): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (11): ReLU()\n",
              "  (12): Dropout2d(p=0.4, inplace=False)\n",
              "  (13): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (14): ReLU()\n",
              "  (15): Flatten(start_dim=1, end_dim=-1)\n",
              "  (16): Linear(in_features=800, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequential_model = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=5, padding=1),\n",
        "            nn.ReLU(),\n",
        "            #nn.Tanh(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout2d(p=0.4),\n",
        "            nn.Conv2d(64, 32, kernel_size=5, padding=1),\n",
        "            nn.ReLU(),\n",
        "            #nn.Tanh(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout2d(p=0.4),\n",
        "            nn.ReLU(),\n",
        "            #nn.Tanh(),\n",
        "            nn.Dropout2d(p=0.4),\n",
        "            nn.Conv2d(32, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(p=0.4),\n",
        "            nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(), \n",
        "            nn.Linear(800, n_out)\n",
        ")\n",
        "\n",
        "model = sequential_model\n",
        "\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0, train_loss: 1.106847, val_loss: 1.136652, val_accuracy: 0.439258, best_score: 0.439258\n",
            "Epoch: 1, train_loss: 0.994765, val_loss: 1.189809, val_accuracy: 0.501623, best_score: 0.501623\n",
            "Epoch: 2, train_loss: 0.937298, val_loss: 1.139109, val_accuracy: 0.528053, best_score: 0.528053\n",
            "Epoch: 3, train_loss: 1.050166, val_loss: 1.087388, val_accuracy: 0.567311, best_score: 0.567311\n",
            "Epoch: 4, train_loss: 0.823521, val_loss: 0.995464, val_accuracy: 0.580603, best_score: 0.580603\n",
            "Epoch: 5, train_loss: 1.064276, val_loss: 0.991035, val_accuracy: 0.592349, best_score: 0.592349\n",
            "Epoch: 6, train_loss: 1.019277, val_loss: 0.944987, val_accuracy: 0.604791, best_score: 0.604791\n",
            "Epoch: 7, train_loss: 0.804702, val_loss: 0.871233, val_accuracy: 0.620015, best_score: 0.620015\n",
            "Epoch: 8, train_loss: 0.929563, val_loss: 0.864298, val_accuracy: 0.626971, best_score: 0.626971\n",
            "Epoch: 9, train_loss: 0.941911, val_loss: 0.797335, val_accuracy: 0.632535, best_score: 0.632535\n",
            "Epoch: 10, train_loss: 0.939530, val_loss: 0.788559, val_accuracy: 0.641190, best_score: 0.641190\n",
            "Epoch: 11, train_loss: 0.880337, val_loss: 0.809143, val_accuracy: 0.645209, best_score: 0.645209\n",
            "Epoch: 12, train_loss: 0.658639, val_loss: 0.757549, val_accuracy: 0.654791, best_score: 0.654791\n",
            "Epoch: 13, train_loss: 0.746390, val_loss: 0.739638, val_accuracy: 0.660201, best_score: 0.660201\n",
            "Epoch: 14, train_loss: 0.758057, val_loss: 0.730155, val_accuracy: 0.664374, best_score: 0.664374\n",
            "Epoch: 15, train_loss: 0.981815, val_loss: 0.722056, val_accuracy: 0.671638, best_score: 0.671638\n",
            "Epoch: 16, train_loss: 0.683079, val_loss: 0.757453, val_accuracy: 0.679907, best_score: 0.679907\n",
            "Epoch: 17, train_loss: 0.720805, val_loss: 0.715378, val_accuracy: 0.687867, best_score: 0.687867\n",
            "Epoch: 18, train_loss: 0.878398, val_loss: 0.729399, val_accuracy: 0.686090, best_score: 0.687867\n",
            "Epoch: 19, train_loss: 0.831994, val_loss: 0.697060, val_accuracy: 0.693895, best_score: 0.693895\n",
            "Epoch: 20, train_loss: 0.886521, val_loss: 0.754547, val_accuracy: 0.691499, best_score: 0.693895\n",
            "Epoch: 21, train_loss: 0.713144, val_loss: 0.733241, val_accuracy: 0.700773, best_score: 0.700773\n",
            "Epoch: 22, train_loss: 0.578000, val_loss: 0.772686, val_accuracy: 0.696445, best_score: 0.700773\n",
            "Epoch: 23, train_loss: 0.857345, val_loss: 0.716395, val_accuracy: 0.708964, best_score: 0.708964\n",
            "Epoch: 24, train_loss: 0.747239, val_loss: 0.712459, val_accuracy: 0.705332, best_score: 0.708964\n",
            "Epoch: 25, train_loss: 0.859924, val_loss: 0.702929, val_accuracy: 0.709583, best_score: 0.709583\n",
            "Epoch: 26, train_loss: 0.681209, val_loss: 0.779038, val_accuracy: 0.711669, best_score: 0.711669\n",
            "Epoch: 27, train_loss: 0.714823, val_loss: 0.818106, val_accuracy: 0.706414, best_score: 0.711669\n",
            "Epoch: 28, train_loss: 0.730708, val_loss: 0.807712, val_accuracy: 0.708733, best_score: 0.711669\n",
            "Epoch: 29, train_loss: 0.746568, val_loss: 0.822028, val_accuracy: 0.713679, best_score: 0.713679\n",
            "Epoch: 30, train_loss: 0.802977, val_loss: 0.790793, val_accuracy: 0.713910, best_score: 0.713910\n",
            "Epoch: 31, train_loss: 0.857973, val_loss: 0.783586, val_accuracy: 0.717774, best_score: 0.717774\n",
            "Epoch: 32, train_loss: 0.734434, val_loss: 0.799670, val_accuracy: 0.715765, best_score: 0.717774\n",
            "Epoch: 33, train_loss: 0.735599, val_loss: 0.777302, val_accuracy: 0.719784, best_score: 0.719784\n",
            "Epoch: 34, train_loss: 0.715111, val_loss: 0.802532, val_accuracy: 0.724420, best_score: 0.724420\n",
            "Epoch: 35, train_loss: 0.669165, val_loss: 0.841290, val_accuracy: 0.713756, best_score: 0.724420\n",
            "Epoch: 36, train_loss: 0.645553, val_loss: 0.820507, val_accuracy: 0.719243, best_score: 0.724420\n",
            "Epoch: 37, train_loss: 0.680058, val_loss: 0.849876, val_accuracy: 0.721406, best_score: 0.724420\n",
            "Epoch: 38, train_loss: 0.713152, val_loss: 0.803686, val_accuracy: 0.717774, best_score: 0.724420\n",
            "Epoch: 39, train_loss: 0.565399, val_loss: 0.828147, val_accuracy: 0.721947, best_score: 0.724420\n",
            "Epoch: 40, train_loss: 0.707786, val_loss: 0.865331, val_accuracy: 0.723107, best_score: 0.724420\n",
            "Epoch: 41, train_loss: 0.606043, val_loss: 0.914918, val_accuracy: 0.723107, best_score: 0.724420\n",
            "Epoch: 42, train_loss: 0.578188, val_loss: 0.873068, val_accuracy: 0.722566, best_score: 0.724420\n",
            "Epoch: 43, train_loss: 0.722241, val_loss: 0.811686, val_accuracy: 0.728207, best_score: 0.728207\n",
            "Epoch: 44, train_loss: 0.681922, val_loss: 0.836208, val_accuracy: 0.722411, best_score: 0.728207\n",
            "Epoch: 45, train_loss: 0.625124, val_loss: 0.872900, val_accuracy: 0.719938, best_score: 0.728207\n",
            "Epoch: 46, train_loss: 0.625836, val_loss: 0.859850, val_accuracy: 0.722798, best_score: 0.728207\n",
            "Epoch: 47, train_loss: 0.741377, val_loss: 0.866335, val_accuracy: 0.726584, best_score: 0.728207\n",
            "Epoch: 48, train_loss: 0.808154, val_loss: 0.949991, val_accuracy: 0.724961, best_score: 0.728207\n",
            "Epoch: 49, train_loss: 0.750641, val_loss: 0.839958, val_accuracy: 0.729057, best_score: 0.729057\n",
            "Epoch: 50, train_loss: 0.639503, val_loss: 0.881538, val_accuracy: 0.731917, best_score: 0.731917\n",
            "Epoch: 51, train_loss: 0.635460, val_loss: 0.903667, val_accuracy: 0.727357, best_score: 0.731917\n",
            "Epoch: 52, train_loss: 0.523478, val_loss: 0.902871, val_accuracy: 0.727434, best_score: 0.731917\n",
            "Epoch: 53, train_loss: 0.649679, val_loss: 0.930986, val_accuracy: 0.725039, best_score: 0.731917\n",
            "Epoch: 54, train_loss: 0.837704, val_loss: 0.898676, val_accuracy: 0.727898, best_score: 0.731917\n",
            "Epoch: 55, train_loss: 0.542680, val_loss: 0.877770, val_accuracy: 0.731453, best_score: 0.731917\n",
            "Epoch: 56, train_loss: 0.777448, val_loss: 0.893420, val_accuracy: 0.730680, best_score: 0.731917\n",
            "Epoch: 57, train_loss: 0.646956, val_loss: 0.903308, val_accuracy: 0.731530, best_score: 0.731917\n",
            "Epoch: 58, train_loss: 0.548015, val_loss: 0.877516, val_accuracy: 0.728594, best_score: 0.731917\n",
            "Epoch: 59, train_loss: 0.570881, val_loss: 0.912239, val_accuracy: 0.729985, best_score: 0.731917\n",
            "Epoch: 60, train_loss: 0.608329, val_loss: 0.845931, val_accuracy: 0.737326, best_score: 0.737326\n",
            "Epoch: 61, train_loss: 0.593435, val_loss: 0.891066, val_accuracy: 0.727975, best_score: 0.737326\n",
            "Epoch: 62, train_loss: 0.678950, val_loss: 0.851693, val_accuracy: 0.734235, best_score: 0.737326\n",
            "Epoch: 63, train_loss: 0.724713, val_loss: 0.904264, val_accuracy: 0.735858, best_score: 0.737326\n",
            "Epoch: 64, train_loss: 0.826772, val_loss: 0.930939, val_accuracy: 0.735394, best_score: 0.737326\n",
            "Epoch: 65, train_loss: 0.753156, val_loss: 0.914365, val_accuracy: 0.733230, best_score: 0.737326\n",
            "Epoch: 66, train_loss: 0.607145, val_loss: 0.944022, val_accuracy: 0.730294, best_score: 0.737326\n",
            "Epoch: 67, train_loss: 0.602209, val_loss: 0.965215, val_accuracy: 0.735471, best_score: 0.737326\n",
            "Epoch: 68, train_loss: 0.734218, val_loss: 0.931440, val_accuracy: 0.735317, best_score: 0.737326\n",
            "Epoch: 69, train_loss: 0.561201, val_loss: 0.879905, val_accuracy: 0.736785, best_score: 0.737326\n",
            "Epoch: 70, train_loss: 0.723594, val_loss: 0.891616, val_accuracy: 0.736399, best_score: 0.737326\n",
            "Epoch: 71, train_loss: 0.674178, val_loss: 0.865938, val_accuracy: 0.738794, best_score: 0.738794\n",
            "Epoch: 72, train_loss: 0.626190, val_loss: 0.993220, val_accuracy: 0.737403, best_score: 0.738794\n",
            "Epoch: 73, train_loss: 0.645676, val_loss: 0.987024, val_accuracy: 0.731917, best_score: 0.738794\n",
            "Epoch: 74, train_loss: 0.773317, val_loss: 0.907738, val_accuracy: 0.730912, best_score: 0.738794\n",
            "Epoch: 75, train_loss: 0.575554, val_loss: 0.963384, val_accuracy: 0.729289, best_score: 0.738794\n",
            "Epoch: 76, train_loss: 0.498754, val_loss: 0.930085, val_accuracy: 0.736167, best_score: 0.738794\n",
            "Epoch: 77, train_loss: 0.606243, val_loss: 0.914974, val_accuracy: 0.739567, best_score: 0.739567\n",
            "Epoch: 78, train_loss: 0.769353, val_loss: 0.905383, val_accuracy: 0.736940, best_score: 0.739567\n",
            "Epoch: 79, train_loss: 0.568347, val_loss: 0.887666, val_accuracy: 0.734389, best_score: 0.739567\n",
            "Epoch: 80, train_loss: 0.506372, val_loss: 0.911914, val_accuracy: 0.734853, best_score: 0.739567\n",
            "Epoch: 81, train_loss: 0.766408, val_loss: 0.919213, val_accuracy: 0.737249, best_score: 0.739567\n",
            "Epoch: 82, train_loss: 0.763110, val_loss: 0.961482, val_accuracy: 0.737017, best_score: 0.739567\n",
            "Epoch: 83, train_loss: 0.644248, val_loss: 0.959614, val_accuracy: 0.739799, best_score: 0.739799\n",
            "Epoch: 84, train_loss: 0.582399, val_loss: 0.904115, val_accuracy: 0.740726, best_score: 0.740726\n",
            "Epoch: 85, train_loss: 0.636564, val_loss: 0.934437, val_accuracy: 0.737867, best_score: 0.740726\n",
            "Epoch: 86, train_loss: 0.744976, val_loss: 0.904973, val_accuracy: 0.739181, best_score: 0.740726\n",
            "Epoch: 87, train_loss: 0.698838, val_loss: 0.926853, val_accuracy: 0.739258, best_score: 0.740726\n",
            "Epoch: 88, train_loss: 0.922142, val_loss: 0.849001, val_accuracy: 0.741577, best_score: 0.741577\n",
            "Epoch: 89, train_loss: 0.779597, val_loss: 0.840475, val_accuracy: 0.742195, best_score: 0.742195\n",
            "Epoch: 90, train_loss: 0.633049, val_loss: 0.913733, val_accuracy: 0.737944, best_score: 0.742195\n",
            "Epoch: 91, train_loss: 0.624358, val_loss: 0.915657, val_accuracy: 0.739722, best_score: 0.742195\n",
            "Epoch: 92, train_loss: 1.066253, val_loss: 0.919507, val_accuracy: 0.740958, best_score: 0.742195\n",
            "Epoch: 93, train_loss: 0.723253, val_loss: 0.925217, val_accuracy: 0.735935, best_score: 0.742195\n",
            "Epoch: 94, train_loss: 0.463068, val_loss: 0.933032, val_accuracy: 0.740340, best_score: 0.742195\n",
            "Epoch: 95, train_loss: 0.518632, val_loss: 0.939324, val_accuracy: 0.736553, best_score: 0.742195\n",
            "Epoch: 96, train_loss: 0.824738, val_loss: 0.866889, val_accuracy: 0.740108, best_score: 0.742195\n",
            "Epoch: 97, train_loss: 0.756086, val_loss: 0.948368, val_accuracy: 0.738331, best_score: 0.742195\n",
            "Epoch: 98, train_loss: 0.868025, val_loss: 0.935132, val_accuracy: 0.742040, best_score: 0.742195\n",
            "Epoch: 99, train_loss: 0.610469, val_loss: 0.910503, val_accuracy: 0.745286, best_score: 0.745286\n",
            "Epoch: 100, train_loss: 0.847084, val_loss: 0.875334, val_accuracy: 0.740495, best_score: 0.745286\n",
            "Epoch: 101, train_loss: 0.481105, val_loss: 0.916197, val_accuracy: 0.740417, best_score: 0.745286\n",
            "Epoch: 102, train_loss: 0.836277, val_loss: 0.950945, val_accuracy: 0.738563, best_score: 0.745286\n",
            "Epoch: 103, train_loss: 0.520027, val_loss: 0.951155, val_accuracy: 0.743045, best_score: 0.745286\n",
            "Epoch: 104, train_loss: 0.542717, val_loss: 0.971783, val_accuracy: 0.739876, best_score: 0.745286\n",
            "Epoch: 105, train_loss: 0.499756, val_loss: 0.900590, val_accuracy: 0.741267, best_score: 0.745286\n",
            "Epoch: 106, train_loss: 0.427339, val_loss: 0.930224, val_accuracy: 0.742040, best_score: 0.745286\n",
            "Epoch: 107, train_loss: 0.596811, val_loss: 0.960033, val_accuracy: 0.739026, best_score: 0.745286\n",
            "Epoch: 108, train_loss: 0.733573, val_loss: 0.961892, val_accuracy: 0.743277, best_score: 0.745286\n",
            "Epoch: 109, train_loss: 0.527877, val_loss: 0.967178, val_accuracy: 0.742736, best_score: 0.745286\n",
            "Epoch: 110, train_loss: 0.606727, val_loss: 0.977211, val_accuracy: 0.746291, best_score: 0.746291\n",
            "Epoch: 111, train_loss: 0.733330, val_loss: 0.979250, val_accuracy: 0.742272, best_score: 0.746291\n",
            "Epoch: 112, train_loss: 0.569736, val_loss: 0.922847, val_accuracy: 0.745131, best_score: 0.746291\n",
            "Epoch: 113, train_loss: 0.611182, val_loss: 0.885306, val_accuracy: 0.745131, best_score: 0.746291\n",
            "Epoch: 114, train_loss: 0.632653, val_loss: 0.905212, val_accuracy: 0.742813, best_score: 0.746291\n",
            "Epoch: 115, train_loss: 0.742622, val_loss: 0.922195, val_accuracy: 0.744668, best_score: 0.746291\n",
            "Epoch: 116, train_loss: 0.573095, val_loss: 0.929814, val_accuracy: 0.741036, best_score: 0.746291\n",
            "Epoch: 117, train_loss: 0.659230, val_loss: 0.984199, val_accuracy: 0.741190, best_score: 0.746291\n",
            "Epoch: 118, train_loss: 0.564155, val_loss: 0.921566, val_accuracy: 0.736862, best_score: 0.746291\n",
            "Epoch: 119, train_loss: 0.622434, val_loss: 0.841307, val_accuracy: 0.742117, best_score: 0.746291\n",
            "Epoch: 120, train_loss: 0.533021, val_loss: 0.935619, val_accuracy: 0.741190, best_score: 0.746291\n",
            "Epoch: 121, train_loss: 0.631476, val_loss: 0.910587, val_accuracy: 0.740263, best_score: 0.746291\n",
            "Epoch: 122, train_loss: 0.633624, val_loss: 0.921985, val_accuracy: 0.746213, best_score: 0.746291\n",
            "Epoch: 123, train_loss: 0.600064, val_loss: 0.950300, val_accuracy: 0.744745, best_score: 0.746291\n",
            "Epoch: 124, train_loss: 0.819531, val_loss: 0.959084, val_accuracy: 0.743199, best_score: 0.746291\n",
            "Epoch: 125, train_loss: 0.730772, val_loss: 0.918310, val_accuracy: 0.744204, best_score: 0.746291\n",
            "Epoch: 126, train_loss: 0.619640, val_loss: 0.926178, val_accuracy: 0.746986, best_score: 0.746986\n",
            "Epoch: 127, train_loss: 0.524457, val_loss: 0.893158, val_accuracy: 0.745595, best_score: 0.746986\n",
            "Epoch: 128, train_loss: 0.475254, val_loss: 0.922880, val_accuracy: 0.743199, best_score: 0.746986\n",
            "Epoch: 129, train_loss: 0.578712, val_loss: 0.931642, val_accuracy: 0.741886, best_score: 0.746986\n",
            "Epoch: 130, train_loss: 0.729405, val_loss: 0.912374, val_accuracy: 0.743895, best_score: 0.746986\n",
            "Epoch: 131, train_loss: 0.780082, val_loss: 0.923235, val_accuracy: 0.747527, best_score: 0.747527\n",
            "Epoch: 132, train_loss: 0.749740, val_loss: 0.925885, val_accuracy: 0.744822, best_score: 0.747527\n",
            "Epoch: 133, train_loss: 0.494561, val_loss: 0.900087, val_accuracy: 0.744513, best_score: 0.747527\n",
            "Epoch: 134, train_loss: 0.791392, val_loss: 0.898791, val_accuracy: 0.743431, best_score: 0.747527\n",
            "Epoch: 135, train_loss: 0.406107, val_loss: 0.955972, val_accuracy: 0.740804, best_score: 0.747527\n",
            "Epoch: 136, train_loss: 0.708811, val_loss: 0.904954, val_accuracy: 0.750850, best_score: 0.750850\n",
            "Epoch: 137, train_loss: 0.585701, val_loss: 0.911798, val_accuracy: 0.744513, best_score: 0.750850\n",
            "Epoch: 138, train_loss: 0.587586, val_loss: 0.921726, val_accuracy: 0.743354, best_score: 0.750850\n",
            "Epoch: 139, train_loss: 0.556997, val_loss: 0.930690, val_accuracy: 0.743354, best_score: 0.750850\n",
            "Epoch: 140, train_loss: 0.604382, val_loss: 0.911953, val_accuracy: 0.748918, best_score: 0.750850\n",
            "Epoch: 141, train_loss: 0.581128, val_loss: 0.906493, val_accuracy: 0.746832, best_score: 0.750850\n",
            "Epoch: 142, train_loss: 0.586651, val_loss: 0.955752, val_accuracy: 0.745518, best_score: 0.750850\n",
            "Epoch: 143, train_loss: 0.776427, val_loss: 0.931750, val_accuracy: 0.747991, best_score: 0.750850\n",
            "Epoch: 144, train_loss: 0.657639, val_loss: 0.925540, val_accuracy: 0.746909, best_score: 0.750850\n",
            "Epoch: 145, train_loss: 0.630121, val_loss: 0.895945, val_accuracy: 0.745981, best_score: 0.750850\n",
            "Epoch: 146, train_loss: 0.535221, val_loss: 0.954380, val_accuracy: 0.740263, best_score: 0.750850\n",
            "Epoch: 147, train_loss: 0.483067, val_loss: 0.940609, val_accuracy: 0.743972, best_score: 0.750850\n",
            "Epoch: 148, train_loss: 0.418866, val_loss: 1.075132, val_accuracy: 0.742349, best_score: 0.750850\n",
            "Epoch: 149, train_loss: 0.560873, val_loss: 0.969440, val_accuracy: 0.745440, best_score: 0.750850\n",
            "Epoch: 150, train_loss: 0.644582, val_loss: 1.015428, val_accuracy: 0.740340, best_score: 0.750850\n",
            "Epoch: 151, train_loss: 0.559434, val_loss: 0.953339, val_accuracy: 0.746445, best_score: 0.750850\n",
            "Epoch: 152, train_loss: 0.553600, val_loss: 0.844774, val_accuracy: 0.747450, best_score: 0.750850\n",
            "Epoch: 153, train_loss: 0.587902, val_loss: 0.914904, val_accuracy: 0.749150, best_score: 0.750850\n",
            "Epoch: 154, train_loss: 0.735108, val_loss: 0.882449, val_accuracy: 0.746677, best_score: 0.750850\n",
            "Epoch: 155, train_loss: 0.530342, val_loss: 0.888139, val_accuracy: 0.745131, best_score: 0.750850\n",
            "Epoch: 156, train_loss: 0.584231, val_loss: 0.862806, val_accuracy: 0.748764, best_score: 0.750850\n",
            "Epoch: 157, train_loss: 0.589117, val_loss: 0.895510, val_accuracy: 0.749073, best_score: 0.750850\n",
            "Epoch: 158, train_loss: 0.731255, val_loss: 0.879713, val_accuracy: 0.748068, best_score: 0.750850\n",
            "Epoch: 159, train_loss: 0.610362, val_loss: 0.941617, val_accuracy: 0.749073, best_score: 0.750850\n",
            "Epoch: 160, train_loss: 0.568327, val_loss: 0.861470, val_accuracy: 0.746986, best_score: 0.750850\n",
            "Epoch: 161, train_loss: 0.516165, val_loss: 0.872551, val_accuracy: 0.744822, best_score: 0.750850\n",
            "Epoch: 162, train_loss: 0.781909, val_loss: 0.841042, val_accuracy: 0.740881, best_score: 0.750850\n",
            "Epoch: 163, train_loss: 0.645467, val_loss: 0.931439, val_accuracy: 0.742504, best_score: 0.750850\n",
            "Epoch: 164, train_loss: 0.622632, val_loss: 0.907167, val_accuracy: 0.743818, best_score: 0.750850\n",
            "Epoch: 165, train_loss: 0.536832, val_loss: 0.867989, val_accuracy: 0.748918, best_score: 0.750850\n",
            "Epoch: 166, train_loss: 0.596795, val_loss: 0.999440, val_accuracy: 0.748609, best_score: 0.750850\n",
            "Epoch: 167, train_loss: 0.562797, val_loss: 0.874197, val_accuracy: 0.749614, best_score: 0.750850\n",
            "Epoch: 168, train_loss: 0.609007, val_loss: 0.983511, val_accuracy: 0.751005, best_score: 0.751005\n",
            "Epoch: 169, train_loss: 0.668023, val_loss: 0.901960, val_accuracy: 0.749536, best_score: 0.751005\n",
            "Epoch: 170, train_loss: 0.664857, val_loss: 0.934582, val_accuracy: 0.749150, best_score: 0.751005\n",
            "Epoch: 171, train_loss: 0.508768, val_loss: 0.900365, val_accuracy: 0.746522, best_score: 0.751005\n",
            "Epoch: 172, train_loss: 0.691802, val_loss: 0.941904, val_accuracy: 0.749923, best_score: 0.751005\n",
            "Epoch: 173, train_loss: 0.383066, val_loss: 0.866086, val_accuracy: 0.747682, best_score: 0.751005\n",
            "Epoch: 174, train_loss: 0.619806, val_loss: 0.978558, val_accuracy: 0.743586, best_score: 0.751005\n",
            "Epoch: 175, train_loss: 0.631791, val_loss: 0.887786, val_accuracy: 0.749923, best_score: 0.751005\n",
            "Epoch: 176, train_loss: 0.718454, val_loss: 0.923814, val_accuracy: 0.747372, best_score: 0.751005\n",
            "Epoch: 177, train_loss: 0.673522, val_loss: 0.858712, val_accuracy: 0.748918, best_score: 0.751005\n",
            "Epoch: 178, train_loss: 0.705243, val_loss: 0.982381, val_accuracy: 0.744668, best_score: 0.751005\n",
            "Epoch: 179, train_loss: 0.423791, val_loss: 0.908629, val_accuracy: 0.750386, best_score: 0.751005\n",
            "Epoch: 180, train_loss: 0.319969, val_loss: 0.930718, val_accuracy: 0.748841, best_score: 0.751005\n",
            "Epoch: 181, train_loss: 0.720794, val_loss: 0.888289, val_accuracy: 0.747604, best_score: 0.751005\n",
            "Epoch: 182, train_loss: 0.546794, val_loss: 0.948618, val_accuracy: 0.743663, best_score: 0.751005\n",
            "Epoch: 183, train_loss: 0.541396, val_loss: 0.956288, val_accuracy: 0.741267, best_score: 0.751005\n",
            "Epoch: 184, train_loss: 0.782690, val_loss: 0.875704, val_accuracy: 0.748995, best_score: 0.751005\n",
            "Epoch: 185, train_loss: 0.731124, val_loss: 0.879994, val_accuracy: 0.748995, best_score: 0.751005\n",
            "Epoch: 186, train_loss: 0.706239, val_loss: 0.831312, val_accuracy: 0.748686, best_score: 0.751005\n",
            "Epoch: 187, train_loss: 0.556456, val_loss: 0.912603, val_accuracy: 0.747759, best_score: 0.751005\n",
            "Epoch: 188, train_loss: 0.414760, val_loss: 0.991953, val_accuracy: 0.745518, best_score: 0.751005\n",
            "Epoch: 189, train_loss: 0.527600, val_loss: 0.921963, val_accuracy: 0.749768, best_score: 0.751005\n",
            "Epoch: 190, train_loss: 0.572725, val_loss: 0.833353, val_accuracy: 0.743972, best_score: 0.751005\n",
            "Epoch: 191, train_loss: 0.612100, val_loss: 0.932721, val_accuracy: 0.743740, best_score: 0.751005\n",
            "Epoch: 192, train_loss: 0.820588, val_loss: 0.878156, val_accuracy: 0.747218, best_score: 0.751005\n",
            "Epoch: 193, train_loss: 0.589495, val_loss: 0.883809, val_accuracy: 0.747759, best_score: 0.751005\n",
            "Epoch: 194, train_loss: 0.738546, val_loss: 0.918432, val_accuracy: 0.743509, best_score: 0.751005\n",
            "Epoch: 195, train_loss: 0.486773, val_loss: 0.841827, val_accuracy: 0.751082, best_score: 0.751082\n",
            "Epoch: 196, train_loss: 0.692603, val_loss: 0.832115, val_accuracy: 0.746291, best_score: 0.751082\n",
            "Epoch: 197, train_loss: 0.573072, val_loss: 0.824501, val_accuracy: 0.747913, best_score: 0.751082\n",
            "Epoch: 198, train_loss: 0.611718, val_loss: 0.863467, val_accuracy: 0.746136, best_score: 0.751082\n",
            "Epoch: 199, train_loss: 0.651384, val_loss: 0.999437, val_accuracy: 0.742968, best_score: 0.751082\n",
            "Epoch: 200, train_loss: 0.809851, val_loss: 0.907752, val_accuracy: 0.748995, best_score: 0.751082\n",
            "Epoch: 201, train_loss: 0.474948, val_loss: 0.929039, val_accuracy: 0.750464, best_score: 0.751082\n",
            "Epoch: 202, train_loss: 0.786253, val_loss: 0.927192, val_accuracy: 0.750309, best_score: 0.751082\n",
            "Epoch: 203, train_loss: 0.665152, val_loss: 0.925919, val_accuracy: 0.746832, best_score: 0.751082\n",
            "Epoch: 204, train_loss: 0.610446, val_loss: 0.854372, val_accuracy: 0.751391, best_score: 0.751391\n",
            "Epoch: 205, train_loss: 0.685804, val_loss: 0.921826, val_accuracy: 0.748918, best_score: 0.751391\n",
            "Epoch: 206, train_loss: 0.533793, val_loss: 0.930737, val_accuracy: 0.746291, best_score: 0.751391\n",
            "Epoch: 207, train_loss: 0.564406, val_loss: 0.907736, val_accuracy: 0.746600, best_score: 0.751391\n",
            "Epoch: 208, train_loss: 0.749534, val_loss: 0.902754, val_accuracy: 0.751005, best_score: 0.751391\n",
            "Epoch: 209, train_loss: 0.525231, val_loss: 0.911018, val_accuracy: 0.750464, best_score: 0.751391\n",
            "Epoch: 210, train_loss: 0.477744, val_loss: 0.929467, val_accuracy: 0.749304, best_score: 0.751391\n",
            "Epoch: 211, train_loss: 0.554833, val_loss: 0.901994, val_accuracy: 0.748764, best_score: 0.751391\n",
            "Epoch: 212, train_loss: 0.626754, val_loss: 0.865731, val_accuracy: 0.752628, best_score: 0.752628\n",
            "Epoch: 213, train_loss: 0.576790, val_loss: 0.928760, val_accuracy: 0.751932, best_score: 0.752628\n",
            "Epoch: 214, train_loss: 0.489841, val_loss: 0.875738, val_accuracy: 0.752782, best_score: 0.752782\n",
            "Epoch: 215, train_loss: 0.595880, val_loss: 0.959807, val_accuracy: 0.747295, best_score: 0.752782\n",
            "Epoch: 216, train_loss: 0.714224, val_loss: 0.944400, val_accuracy: 0.751236, best_score: 0.752782\n",
            "Epoch: 217, train_loss: 0.514121, val_loss: 0.942406, val_accuracy: 0.754096, best_score: 0.754096\n",
            "Epoch: 218, train_loss: 0.667123, val_loss: 0.981915, val_accuracy: 0.749150, best_score: 0.754096\n",
            "Epoch: 219, train_loss: 0.601381, val_loss: 0.957790, val_accuracy: 0.753864, best_score: 0.754096\n",
            "Epoch: 220, train_loss: 0.399480, val_loss: 0.930093, val_accuracy: 0.749073, best_score: 0.754096\n",
            "Epoch: 221, train_loss: 0.744716, val_loss: 0.898490, val_accuracy: 0.749536, best_score: 0.754096\n",
            "Epoch: 222, train_loss: 0.452901, val_loss: 0.986046, val_accuracy: 0.750541, best_score: 0.754096\n",
            "Epoch: 223, train_loss: 0.677853, val_loss: 0.889678, val_accuracy: 0.751700, best_score: 0.754096\n",
            "Epoch: 224, train_loss: 0.785337, val_loss: 0.944227, val_accuracy: 0.753400, best_score: 0.754096\n",
            "Epoch: 225, train_loss: 0.822709, val_loss: 0.875169, val_accuracy: 0.748764, best_score: 0.754096\n",
            "Epoch: 226, train_loss: 0.729435, val_loss: 0.928810, val_accuracy: 0.743199, best_score: 0.754096\n",
            "Epoch: 227, train_loss: 0.475386, val_loss: 0.925420, val_accuracy: 0.750000, best_score: 0.754096\n",
            "Epoch: 228, train_loss: 0.451121, val_loss: 0.947914, val_accuracy: 0.753014, best_score: 0.754096\n",
            "Epoch: 229, train_loss: 0.597566, val_loss: 0.873603, val_accuracy: 0.752318, best_score: 0.754096\n",
            "Epoch: 230, train_loss: 0.466036, val_loss: 0.935998, val_accuracy: 0.744745, best_score: 0.754096\n",
            "Epoch: 231, train_loss: 0.616250, val_loss: 1.006699, val_accuracy: 0.746600, best_score: 0.754096\n",
            "Epoch: 232, train_loss: 0.724776, val_loss: 0.940728, val_accuracy: 0.748918, best_score: 0.754096\n",
            "Epoch: 233, train_loss: 0.740886, val_loss: 0.961816, val_accuracy: 0.750232, best_score: 0.754096\n",
            "Epoch: 234, train_loss: 0.721376, val_loss: 0.928831, val_accuracy: 0.752859, best_score: 0.754096\n",
            "Epoch: 235, train_loss: 0.776548, val_loss: 0.951438, val_accuracy: 0.750077, best_score: 0.754096\n",
            "Epoch: 236, train_loss: 0.666772, val_loss: 0.949621, val_accuracy: 0.748764, best_score: 0.754096\n",
            "Epoch: 237, train_loss: 0.573210, val_loss: 0.934130, val_accuracy: 0.743045, best_score: 0.754096\n",
            "Epoch: 238, train_loss: 0.499529, val_loss: 0.881898, val_accuracy: 0.750927, best_score: 0.754096\n",
            "Epoch: 239, train_loss: 0.728581, val_loss: 0.996534, val_accuracy: 0.748841, best_score: 0.754096\n",
            "Epoch: 240, train_loss: 0.505727, val_loss: 0.933785, val_accuracy: 0.750464, best_score: 0.754096\n",
            "Epoch: 241, train_loss: 0.618344, val_loss: 0.945242, val_accuracy: 0.746832, best_score: 0.754096\n",
            "Epoch: 242, train_loss: 0.526172, val_loss: 1.000169, val_accuracy: 0.747991, best_score: 0.754096\n",
            "Epoch: 243, train_loss: 0.509969, val_loss: 0.939122, val_accuracy: 0.753864, best_score: 0.754096\n",
            "Epoch: 244, train_loss: 0.474852, val_loss: 0.945017, val_accuracy: 0.749382, best_score: 0.754096\n",
            "Epoch: 245, train_loss: 0.803104, val_loss: 0.963622, val_accuracy: 0.750541, best_score: 0.754096\n",
            "Epoch: 246, train_loss: 0.753211, val_loss: 0.903407, val_accuracy: 0.748995, best_score: 0.754096\n",
            "Epoch: 247, train_loss: 0.734790, val_loss: 0.864457, val_accuracy: 0.752705, best_score: 0.754096\n",
            "Epoch: 248, train_loss: 0.755949, val_loss: 0.916200, val_accuracy: 0.746368, best_score: 0.754096\n",
            "Epoch: 249, train_loss: 0.707008, val_loss: 0.872109, val_accuracy: 0.751777, best_score: 0.754096\n",
            "Epoch: 250, train_loss: 0.389350, val_loss: 0.915599, val_accuracy: 0.748995, best_score: 0.754096\n",
            "Epoch: 251, train_loss: 0.613028, val_loss: 0.843985, val_accuracy: 0.750464, best_score: 0.754096\n",
            "Epoch: 252, train_loss: 0.927899, val_loss: 0.920790, val_accuracy: 0.749227, best_score: 0.754096\n",
            "Epoch: 253, train_loss: 0.637610, val_loss: 0.966332, val_accuracy: 0.746677, best_score: 0.754096\n",
            "Epoch: 254, train_loss: 0.599830, val_loss: 0.975484, val_accuracy: 0.751546, best_score: 0.754096\n",
            "Epoch: 255, train_loss: 0.575665, val_loss: 0.957946, val_accuracy: 0.753400, best_score: 0.754096\n",
            "Epoch: 256, train_loss: 0.601195, val_loss: 0.913683, val_accuracy: 0.752550, best_score: 0.754096\n",
            "Epoch: 257, train_loss: 0.526508, val_loss: 0.946521, val_accuracy: 0.751855, best_score: 0.754096\n",
            "Epoch: 258, train_loss: 0.591310, val_loss: 0.963274, val_accuracy: 0.750541, best_score: 0.754096\n",
            "Epoch: 259, train_loss: 0.638058, val_loss: 0.932155, val_accuracy: 0.753555, best_score: 0.754096\n",
            "Epoch: 260, train_loss: 0.616977, val_loss: 0.942342, val_accuracy: 0.752705, best_score: 0.754096\n",
            "Epoch: 261, train_loss: 0.621461, val_loss: 0.920509, val_accuracy: 0.748764, best_score: 0.754096\n",
            "Epoch: 262, train_loss: 0.440111, val_loss: 0.947821, val_accuracy: 0.747682, best_score: 0.754096\n",
            "Epoch: 263, train_loss: 0.450103, val_loss: 0.855270, val_accuracy: 0.751005, best_score: 0.754096\n",
            "Epoch: 264, train_loss: 0.778172, val_loss: 0.842639, val_accuracy: 0.749382, best_score: 0.754096\n",
            "Epoch: 265, train_loss: 0.527758, val_loss: 0.849020, val_accuracy: 0.749768, best_score: 0.754096\n",
            "Epoch: 266, train_loss: 0.681691, val_loss: 0.893261, val_accuracy: 0.751546, best_score: 0.754096\n",
            "Epoch: 267, train_loss: 0.767998, val_loss: 0.906277, val_accuracy: 0.749768, best_score: 0.754096\n",
            "Epoch: 268, train_loss: 0.594969, val_loss: 0.961530, val_accuracy: 0.746754, best_score: 0.754096\n",
            "Epoch: 269, train_loss: 0.650552, val_loss: 0.919190, val_accuracy: 0.748068, best_score: 0.754096\n",
            "Epoch: 270, train_loss: 0.782754, val_loss: 0.859966, val_accuracy: 0.751314, best_score: 0.754096\n",
            "Epoch: 271, train_loss: 0.554857, val_loss: 0.978058, val_accuracy: 0.750309, best_score: 0.754096\n",
            "Epoch: 272, train_loss: 0.603340, val_loss: 1.000248, val_accuracy: 0.747450, best_score: 0.754096\n",
            "Epoch: 273, train_loss: 0.535256, val_loss: 0.929762, val_accuracy: 0.752164, best_score: 0.754096\n",
            "Epoch: 274, train_loss: 0.521681, val_loss: 1.053412, val_accuracy: 0.750618, best_score: 0.754096\n",
            "Epoch: 275, train_loss: 0.578725, val_loss: 0.974229, val_accuracy: 0.753168, best_score: 0.754096\n",
            "Epoch: 276, train_loss: 0.593711, val_loss: 0.997934, val_accuracy: 0.750000, best_score: 0.754096\n",
            "Epoch: 277, train_loss: 0.552450, val_loss: 1.001532, val_accuracy: 0.750386, best_score: 0.754096\n",
            "Epoch: 278, train_loss: 0.579933, val_loss: 0.986246, val_accuracy: 0.749227, best_score: 0.754096\n",
            "Epoch: 279, train_loss: 0.509463, val_loss: 0.944559, val_accuracy: 0.749073, best_score: 0.754096\n",
            "Epoch: 280, train_loss: 0.651455, val_loss: 1.033693, val_accuracy: 0.749150, best_score: 0.754096\n",
            "Epoch: 281, train_loss: 0.495946, val_loss: 0.936699, val_accuracy: 0.749923, best_score: 0.754096\n",
            "Epoch: 282, train_loss: 0.717234, val_loss: 1.046523, val_accuracy: 0.749227, best_score: 0.754096\n",
            "Epoch: 283, train_loss: 0.634103, val_loss: 0.934046, val_accuracy: 0.745518, best_score: 0.754096\n",
            "Epoch: 284, train_loss: 0.510497, val_loss: 0.914022, val_accuracy: 0.753246, best_score: 0.754096\n",
            "Epoch: 285, train_loss: 0.492238, val_loss: 0.944674, val_accuracy: 0.753478, best_score: 0.754096\n",
            "Epoch: 286, train_loss: 0.516603, val_loss: 0.984919, val_accuracy: 0.749614, best_score: 0.754096\n",
            "Epoch: 287, train_loss: 0.683429, val_loss: 0.978345, val_accuracy: 0.747141, best_score: 0.754096\n",
            "Epoch: 288, train_loss: 0.529484, val_loss: 0.923815, val_accuracy: 0.754019, best_score: 0.754096\n",
            "Epoch: 289, train_loss: 0.497613, val_loss: 0.972357, val_accuracy: 0.742968, best_score: 0.754096\n",
            "Epoch: 290, train_loss: 0.605216, val_loss: 0.993481, val_accuracy: 0.747527, best_score: 0.754096\n",
            "Epoch: 291, train_loss: 0.737824, val_loss: 0.949042, val_accuracy: 0.749382, best_score: 0.754096\n",
            "Epoch: 292, train_loss: 0.649246, val_loss: 0.887445, val_accuracy: 0.752241, best_score: 0.754096\n",
            "Epoch: 293, train_loss: 0.480235, val_loss: 0.967947, val_accuracy: 0.752782, best_score: 0.754096\n",
            "Epoch: 294, train_loss: 0.639134, val_loss: 0.969419, val_accuracy: 0.752087, best_score: 0.754096\n",
            "Epoch: 295, train_loss: 0.695952, val_loss: 0.874903, val_accuracy: 0.749768, best_score: 0.754096\n",
            "Epoch: 296, train_loss: 0.617567, val_loss: 1.003265, val_accuracy: 0.753246, best_score: 0.754096\n",
            "Epoch: 297, train_loss: 0.734874, val_loss: 0.985120, val_accuracy: 0.751855, best_score: 0.754096\n",
            "Epoch: 298, train_loss: 0.662609, val_loss: 0.960192, val_accuracy: 0.755332, best_score: 0.755332\n",
            "Epoch: 299, train_loss: 0.613310, val_loss: 0.997992, val_accuracy: 0.746136, best_score: 0.755332\n",
            "Epoch: 300, train_loss: 0.589387, val_loss: 1.020339, val_accuracy: 0.749845, best_score: 0.755332\n",
            "Epoch: 301, train_loss: 0.610319, val_loss: 0.987162, val_accuracy: 0.751005, best_score: 0.755332\n",
            "Epoch: 302, train_loss: 0.627434, val_loss: 0.958526, val_accuracy: 0.748223, best_score: 0.755332\n",
            "Epoch: 303, train_loss: 0.564494, val_loss: 0.897984, val_accuracy: 0.753709, best_score: 0.755332\n",
            "Epoch: 304, train_loss: 0.681283, val_loss: 1.021708, val_accuracy: 0.745054, best_score: 0.755332\n",
            "Epoch: 305, train_loss: 0.423906, val_loss: 1.028631, val_accuracy: 0.752628, best_score: 0.755332\n",
            "Epoch: 306, train_loss: 0.859510, val_loss: 1.024571, val_accuracy: 0.750464, best_score: 0.755332\n",
            "Epoch: 307, train_loss: 0.757747, val_loss: 0.978466, val_accuracy: 0.753168, best_score: 0.755332\n",
            "Epoch: 308, train_loss: 0.610380, val_loss: 0.983920, val_accuracy: 0.752705, best_score: 0.755332\n",
            "Epoch: 309, train_loss: 0.571956, val_loss: 0.973912, val_accuracy: 0.751082, best_score: 0.755332\n",
            "Epoch: 310, train_loss: 0.524224, val_loss: 0.931494, val_accuracy: 0.750232, best_score: 0.755332\n",
            "Epoch: 311, train_loss: 0.509522, val_loss: 0.959961, val_accuracy: 0.749845, best_score: 0.755332\n",
            "Epoch: 312, train_loss: 0.674020, val_loss: 0.950197, val_accuracy: 0.754791, best_score: 0.755332\n",
            "Epoch: 313, train_loss: 0.523339, val_loss: 1.004107, val_accuracy: 0.746522, best_score: 0.755332\n",
            "Epoch: 314, train_loss: 0.526464, val_loss: 0.943852, val_accuracy: 0.756337, best_score: 0.756337\n",
            "Epoch: 315, train_loss: 0.507350, val_loss: 0.882433, val_accuracy: 0.755796, best_score: 0.756337\n",
            "Epoch: 316, train_loss: 0.625175, val_loss: 0.951934, val_accuracy: 0.747682, best_score: 0.756337\n",
            "Epoch: 317, train_loss: 0.640991, val_loss: 0.995564, val_accuracy: 0.752087, best_score: 0.756337\n",
            "Epoch: 318, train_loss: 0.730393, val_loss: 0.950667, val_accuracy: 0.753091, best_score: 0.756337\n",
            "Epoch: 319, train_loss: 0.812946, val_loss: 0.906569, val_accuracy: 0.753168, best_score: 0.756337\n",
            "Epoch: 320, train_loss: 0.462554, val_loss: 0.905732, val_accuracy: 0.753555, best_score: 0.756337\n",
            "Epoch: 321, train_loss: 0.729759, val_loss: 0.917597, val_accuracy: 0.754250, best_score: 0.756337\n",
            "Epoch: 322, train_loss: 0.632979, val_loss: 1.039341, val_accuracy: 0.744668, best_score: 0.756337\n",
            "Epoch: 323, train_loss: 0.562311, val_loss: 0.953100, val_accuracy: 0.751236, best_score: 0.756337\n",
            "Epoch: 324, train_loss: 0.482593, val_loss: 1.050450, val_accuracy: 0.748532, best_score: 0.756337\n",
            "Epoch: 325, train_loss: 0.424400, val_loss: 0.975315, val_accuracy: 0.751932, best_score: 0.756337\n",
            "Epoch: 326, train_loss: 0.744552, val_loss: 0.915672, val_accuracy: 0.750155, best_score: 0.756337\n",
            "Epoch: 327, train_loss: 0.739850, val_loss: 1.001902, val_accuracy: 0.744127, best_score: 0.756337\n",
            "Epoch: 328, train_loss: 0.468220, val_loss: 0.999926, val_accuracy: 0.749768, best_score: 0.756337\n",
            "Epoch: 329, train_loss: 0.749753, val_loss: 0.910774, val_accuracy: 0.753787, best_score: 0.756337\n",
            "Epoch: 330, train_loss: 0.744256, val_loss: 1.008037, val_accuracy: 0.750077, best_score: 0.756337\n",
            "Epoch: 331, train_loss: 0.690296, val_loss: 0.964116, val_accuracy: 0.754173, best_score: 0.756337\n",
            "Epoch: 332, train_loss: 0.493242, val_loss: 0.944462, val_accuracy: 0.752782, best_score: 0.756337\n",
            "Epoch: 333, train_loss: 0.440388, val_loss: 0.947215, val_accuracy: 0.754019, best_score: 0.756337\n",
            "Epoch: 334, train_loss: 0.594422, val_loss: 1.013896, val_accuracy: 0.753400, best_score: 0.756337\n",
            "Epoch: 335, train_loss: 0.439178, val_loss: 1.038283, val_accuracy: 0.749536, best_score: 0.756337\n",
            "Epoch: 336, train_loss: 0.709180, val_loss: 1.022516, val_accuracy: 0.749304, best_score: 0.756337\n",
            "Epoch: 337, train_loss: 0.599746, val_loss: 0.978820, val_accuracy: 0.750618, best_score: 0.756337\n",
            "Epoch: 338, train_loss: 0.512633, val_loss: 1.033823, val_accuracy: 0.754173, best_score: 0.756337\n",
            "Epoch: 339, train_loss: 0.683057, val_loss: 0.947328, val_accuracy: 0.749382, best_score: 0.756337\n",
            "Epoch: 340, train_loss: 0.772256, val_loss: 0.929915, val_accuracy: 0.752705, best_score: 0.756337\n",
            "Epoch: 341, train_loss: 0.799635, val_loss: 0.992115, val_accuracy: 0.750850, best_score: 0.756337\n",
            "Epoch: 342, train_loss: 0.483877, val_loss: 0.920973, val_accuracy: 0.758655, best_score: 0.758655\n",
            "Epoch: 343, train_loss: 0.770197, val_loss: 1.024141, val_accuracy: 0.748918, best_score: 0.758655\n",
            "Epoch: 344, train_loss: 0.523148, val_loss: 1.022515, val_accuracy: 0.752705, best_score: 0.758655\n",
            "Epoch: 345, train_loss: 0.732830, val_loss: 0.960065, val_accuracy: 0.754482, best_score: 0.758655\n",
            "Epoch: 346, train_loss: 0.608609, val_loss: 0.967268, val_accuracy: 0.752705, best_score: 0.758655\n",
            "Epoch: 347, train_loss: 0.708977, val_loss: 0.896366, val_accuracy: 0.745904, best_score: 0.758655\n",
            "Epoch: 348, train_loss: 0.450314, val_loss: 0.961725, val_accuracy: 0.755332, best_score: 0.758655\n",
            "Epoch: 349, train_loss: 0.656326, val_loss: 0.935682, val_accuracy: 0.755332, best_score: 0.758655\n",
            "Epoch: 350, train_loss: 0.605846, val_loss: 1.018583, val_accuracy: 0.747604, best_score: 0.758655\n",
            "Epoch: 351, train_loss: 0.510015, val_loss: 0.971782, val_accuracy: 0.745131, best_score: 0.758655\n",
            "Epoch: 352, train_loss: 0.635707, val_loss: 0.969274, val_accuracy: 0.754714, best_score: 0.758655\n",
            "Epoch: 353, train_loss: 0.671805, val_loss: 1.038136, val_accuracy: 0.748532, best_score: 0.758655\n",
            "Epoch: 354, train_loss: 0.527574, val_loss: 0.992476, val_accuracy: 0.756646, best_score: 0.758655\n",
            "Epoch: 355, train_loss: 0.585549, val_loss: 0.948785, val_accuracy: 0.747836, best_score: 0.758655\n",
            "Epoch: 356, train_loss: 0.538086, val_loss: 0.900284, val_accuracy: 0.754560, best_score: 0.758655\n",
            "Epoch: 357, train_loss: 0.583154, val_loss: 0.904689, val_accuracy: 0.747604, best_score: 0.758655\n",
            "Epoch: 358, train_loss: 0.516905, val_loss: 1.021713, val_accuracy: 0.752473, best_score: 0.758655\n",
            "Epoch: 359, train_loss: 0.752924, val_loss: 1.008753, val_accuracy: 0.754791, best_score: 0.758655\n",
            "Epoch: 360, train_loss: 0.659638, val_loss: 1.073777, val_accuracy: 0.751082, best_score: 0.758655\n",
            "Epoch: 361, train_loss: 0.596145, val_loss: 0.998389, val_accuracy: 0.753787, best_score: 0.758655\n",
            "Epoch: 362, train_loss: 0.726878, val_loss: 0.982027, val_accuracy: 0.749304, best_score: 0.758655\n",
            "Epoch: 363, train_loss: 0.618361, val_loss: 1.033509, val_accuracy: 0.745672, best_score: 0.758655\n",
            "Epoch: 364, train_loss: 0.575701, val_loss: 0.944943, val_accuracy: 0.753323, best_score: 0.758655\n",
            "Epoch: 365, train_loss: 0.569758, val_loss: 1.003151, val_accuracy: 0.751159, best_score: 0.758655\n",
            "Epoch: 366, train_loss: 0.779792, val_loss: 0.984381, val_accuracy: 0.749845, best_score: 0.758655\n",
            "Epoch: 367, train_loss: 0.507360, val_loss: 0.981169, val_accuracy: 0.752937, best_score: 0.758655\n",
            "Epoch: 368, train_loss: 0.825082, val_loss: 0.957848, val_accuracy: 0.753787, best_score: 0.758655\n",
            "Epoch: 369, train_loss: 0.561083, val_loss: 0.991650, val_accuracy: 0.755100, best_score: 0.758655\n",
            "Epoch: 370, train_loss: 0.669270, val_loss: 0.893217, val_accuracy: 0.756337, best_score: 0.758655\n",
            "Epoch: 371, train_loss: 0.635033, val_loss: 0.950054, val_accuracy: 0.754173, best_score: 0.758655\n",
            "Epoch: 372, train_loss: 0.718562, val_loss: 0.937220, val_accuracy: 0.752087, best_score: 0.758655\n",
            "Epoch: 373, train_loss: 0.522870, val_loss: 0.951221, val_accuracy: 0.755719, best_score: 0.758655\n",
            "Epoch: 374, train_loss: 0.466539, val_loss: 0.980647, val_accuracy: 0.751236, best_score: 0.758655\n",
            "Epoch: 375, train_loss: 0.625191, val_loss: 1.028490, val_accuracy: 0.751700, best_score: 0.758655\n",
            "Epoch: 376, train_loss: 0.511033, val_loss: 1.038944, val_accuracy: 0.742427, best_score: 0.758655\n",
            "Epoch: 377, train_loss: 0.615413, val_loss: 0.984412, val_accuracy: 0.759119, best_score: 0.759119\n",
            "Epoch: 378, train_loss: 0.473728, val_loss: 1.000808, val_accuracy: 0.755487, best_score: 0.759119\n",
            "Epoch: 379, train_loss: 0.637801, val_loss: 1.090654, val_accuracy: 0.753323, best_score: 0.759119\n",
            "Epoch: 380, train_loss: 0.581607, val_loss: 0.980633, val_accuracy: 0.753168, best_score: 0.759119\n",
            "Epoch: 381, train_loss: 0.669663, val_loss: 0.947805, val_accuracy: 0.747913, best_score: 0.759119\n",
            "Epoch: 382, train_loss: 0.640334, val_loss: 0.963912, val_accuracy: 0.751700, best_score: 0.759119\n",
            "Epoch: 383, train_loss: 0.812074, val_loss: 0.933703, val_accuracy: 0.754405, best_score: 0.759119\n",
            "Epoch: 384, train_loss: 0.534691, val_loss: 0.959746, val_accuracy: 0.748841, best_score: 0.759119\n",
            "Epoch: 385, train_loss: 0.590517, val_loss: 0.922532, val_accuracy: 0.753941, best_score: 0.759119\n",
            "Epoch: 386, train_loss: 0.657009, val_loss: 1.013766, val_accuracy: 0.747836, best_score: 0.759119\n",
            "Epoch: 387, train_loss: 0.634304, val_loss: 0.933801, val_accuracy: 0.753864, best_score: 0.759119\n",
            "Epoch: 388, train_loss: 0.611309, val_loss: 0.968460, val_accuracy: 0.750232, best_score: 0.759119\n",
            "Epoch: 389, train_loss: 0.707097, val_loss: 1.021203, val_accuracy: 0.755796, best_score: 0.759119\n",
            "Epoch: 390, train_loss: 0.840976, val_loss: 0.993305, val_accuracy: 0.753555, best_score: 0.759119\n",
            "Epoch: 391, train_loss: 0.681477, val_loss: 0.910739, val_accuracy: 0.754173, best_score: 0.759119\n",
            "Epoch: 392, train_loss: 0.657209, val_loss: 0.965903, val_accuracy: 0.753632, best_score: 0.759119\n",
            "Epoch: 393, train_loss: 0.553221, val_loss: 0.946001, val_accuracy: 0.750232, best_score: 0.759119\n",
            "Epoch: 394, train_loss: 0.579330, val_loss: 1.021479, val_accuracy: 0.752396, best_score: 0.759119\n",
            "Epoch: 395, train_loss: 0.680925, val_loss: 0.970367, val_accuracy: 0.751391, best_score: 0.759119\n",
            "Epoch: 396, train_loss: 0.652286, val_loss: 0.883306, val_accuracy: 0.754405, best_score: 0.759119\n",
            "Epoch: 397, train_loss: 0.771890, val_loss: 0.952006, val_accuracy: 0.753941, best_score: 0.759119\n",
            "Epoch: 398, train_loss: 0.630792, val_loss: 0.987605, val_accuracy: 0.753787, best_score: 0.759119\n",
            "Epoch: 399, train_loss: 0.540416, val_loss: 0.933727, val_accuracy: 0.754946, best_score: 0.759119\n",
            "Epoch: 400, train_loss: 0.465278, val_loss: 0.926101, val_accuracy: 0.753632, best_score: 0.759119\n",
            "Epoch: 401, train_loss: 0.455804, val_loss: 0.969519, val_accuracy: 0.753400, best_score: 0.759119\n",
            "Epoch: 402, train_loss: 0.547563, val_loss: 0.982036, val_accuracy: 0.749073, best_score: 0.759119\n",
            "Epoch: 403, train_loss: 0.681401, val_loss: 0.955085, val_accuracy: 0.752550, best_score: 0.759119\n",
            "Epoch: 404, train_loss: 0.455451, val_loss: 0.970919, val_accuracy: 0.754405, best_score: 0.759119\n",
            "Epoch: 405, train_loss: 0.502755, val_loss: 0.989189, val_accuracy: 0.755178, best_score: 0.759119\n",
            "Epoch: 406, train_loss: 0.542324, val_loss: 0.952269, val_accuracy: 0.751236, best_score: 0.759119\n",
            "Epoch: 407, train_loss: 0.397874, val_loss: 0.942003, val_accuracy: 0.751082, best_score: 0.759119\n",
            "Epoch: 408, train_loss: 0.603777, val_loss: 0.947397, val_accuracy: 0.752009, best_score: 0.759119\n",
            "Epoch: 409, train_loss: 0.601086, val_loss: 0.991662, val_accuracy: 0.747063, best_score: 0.759119\n",
            "Epoch: 410, train_loss: 0.573188, val_loss: 0.919546, val_accuracy: 0.748686, best_score: 0.759119\n",
            "Epoch: 411, train_loss: 0.541199, val_loss: 0.923413, val_accuracy: 0.754019, best_score: 0.759119\n",
            "Epoch: 412, train_loss: 0.591418, val_loss: 0.941103, val_accuracy: 0.754482, best_score: 0.759119\n",
            "Epoch: 413, train_loss: 0.445293, val_loss: 0.984242, val_accuracy: 0.752782, best_score: 0.759119\n",
            "Epoch: 414, train_loss: 0.623622, val_loss: 0.960555, val_accuracy: 0.749768, best_score: 0.759119\n",
            "Epoch: 415, train_loss: 0.673480, val_loss: 0.926160, val_accuracy: 0.751623, best_score: 0.759119\n",
            "Epoch: 416, train_loss: 0.612202, val_loss: 0.878773, val_accuracy: 0.755641, best_score: 0.759119\n",
            "Epoch: 417, train_loss: 0.522271, val_loss: 0.928139, val_accuracy: 0.744977, best_score: 0.759119\n",
            "Epoch: 418, train_loss: 0.660267, val_loss: 0.973743, val_accuracy: 0.749227, best_score: 0.759119\n",
            "Epoch: 419, train_loss: 0.476560, val_loss: 0.897085, val_accuracy: 0.756337, best_score: 0.759119\n",
            "Epoch: 420, train_loss: 0.741480, val_loss: 0.916472, val_accuracy: 0.754869, best_score: 0.759119\n",
            "Epoch: 421, train_loss: 0.481713, val_loss: 0.946855, val_accuracy: 0.752859, best_score: 0.759119\n",
            "Epoch: 422, train_loss: 0.720885, val_loss: 0.991308, val_accuracy: 0.749304, best_score: 0.759119\n",
            "Epoch: 423, train_loss: 0.652862, val_loss: 0.873924, val_accuracy: 0.754328, best_score: 0.759119\n",
            "Epoch: 424, train_loss: 0.491933, val_loss: 0.913623, val_accuracy: 0.750000, best_score: 0.759119\n",
            "Epoch: 425, train_loss: 0.606499, val_loss: 0.919092, val_accuracy: 0.756646, best_score: 0.759119\n",
            "Epoch: 426, train_loss: 0.701985, val_loss: 0.968129, val_accuracy: 0.750077, best_score: 0.759119\n",
            "Epoch: 427, train_loss: 0.487004, val_loss: 0.974122, val_accuracy: 0.750232, best_score: 0.759119\n",
            "Epoch: 428, train_loss: 0.468865, val_loss: 1.033196, val_accuracy: 0.753478, best_score: 0.759119\n",
            "Epoch: 429, train_loss: 0.539033, val_loss: 0.948419, val_accuracy: 0.753014, best_score: 0.759119\n",
            "Epoch: 430, train_loss: 0.623047, val_loss: 0.949526, val_accuracy: 0.750850, best_score: 0.759119\n",
            "Epoch: 431, train_loss: 0.668400, val_loss: 1.018454, val_accuracy: 0.750618, best_score: 0.759119\n",
            "Epoch: 432, train_loss: 0.412833, val_loss: 0.979040, val_accuracy: 0.752009, best_score: 0.759119\n",
            "Epoch: 433, train_loss: 0.400645, val_loss: 0.948451, val_accuracy: 0.749691, best_score: 0.759119\n",
            "Epoch: 434, train_loss: 0.784456, val_loss: 0.997042, val_accuracy: 0.750927, best_score: 0.759119\n",
            "Epoch: 435, train_loss: 0.618869, val_loss: 0.878876, val_accuracy: 0.755719, best_score: 0.759119\n",
            "Epoch: 436, train_loss: 0.529665, val_loss: 0.943518, val_accuracy: 0.753168, best_score: 0.759119\n",
            "Epoch: 437, train_loss: 0.530707, val_loss: 0.952768, val_accuracy: 0.755564, best_score: 0.759119\n",
            "Epoch: 438, train_loss: 0.597334, val_loss: 0.898322, val_accuracy: 0.754250, best_score: 0.759119\n",
            "Epoch: 439, train_loss: 0.629169, val_loss: 0.879147, val_accuracy: 0.757342, best_score: 0.759119\n",
            "Epoch: 440, train_loss: 0.519128, val_loss: 0.915781, val_accuracy: 0.754946, best_score: 0.759119\n",
            "Epoch: 441, train_loss: 0.718931, val_loss: 0.976344, val_accuracy: 0.751468, best_score: 0.759119\n",
            "Epoch: 442, train_loss: 0.682878, val_loss: 0.950331, val_accuracy: 0.754714, best_score: 0.759119\n",
            "Epoch: 443, train_loss: 0.506726, val_loss: 0.922668, val_accuracy: 0.749536, best_score: 0.759119\n",
            "Epoch: 444, train_loss: 0.811080, val_loss: 0.960016, val_accuracy: 0.753478, best_score: 0.759119\n",
            "Epoch: 445, train_loss: 0.579105, val_loss: 0.960870, val_accuracy: 0.752318, best_score: 0.759119\n",
            "Epoch: 446, train_loss: 0.434158, val_loss: 0.998773, val_accuracy: 0.753787, best_score: 0.759119\n",
            "Epoch: 447, train_loss: 0.764636, val_loss: 0.998564, val_accuracy: 0.752782, best_score: 0.759119\n",
            "Epoch: 448, train_loss: 0.497332, val_loss: 0.992518, val_accuracy: 0.749923, best_score: 0.759119\n",
            "Epoch: 449, train_loss: 0.960927, val_loss: 0.913710, val_accuracy: 0.753478, best_score: 0.759119\n",
            "Epoch: 450, train_loss: 0.585797, val_loss: 0.938433, val_accuracy: 0.757264, best_score: 0.759119\n",
            "Epoch: 451, train_loss: 0.771194, val_loss: 0.999925, val_accuracy: 0.748764, best_score: 0.759119\n",
            "Epoch: 452, train_loss: 0.486585, val_loss: 0.940570, val_accuracy: 0.754482, best_score: 0.759119\n",
            "Epoch: 453, train_loss: 0.525710, val_loss: 0.978536, val_accuracy: 0.746213, best_score: 0.759119\n",
            "Epoch: 454, train_loss: 0.665031, val_loss: 1.022552, val_accuracy: 0.750618, best_score: 0.759119\n",
            "Epoch: 455, train_loss: 0.488790, val_loss: 0.980762, val_accuracy: 0.749923, best_score: 0.759119\n",
            "Epoch: 456, train_loss: 0.724083, val_loss: 1.050642, val_accuracy: 0.749614, best_score: 0.759119\n",
            "Epoch: 457, train_loss: 0.604099, val_loss: 0.954187, val_accuracy: 0.755100, best_score: 0.759119\n",
            "Epoch: 458, train_loss: 0.483217, val_loss: 0.958250, val_accuracy: 0.754173, best_score: 0.759119\n",
            "Epoch: 459, train_loss: 0.573423, val_loss: 0.996654, val_accuracy: 0.753246, best_score: 0.759119\n",
            "Epoch: 460, train_loss: 0.555563, val_loss: 0.933442, val_accuracy: 0.752087, best_score: 0.759119\n",
            "Epoch: 461, train_loss: 0.510140, val_loss: 0.995886, val_accuracy: 0.750077, best_score: 0.759119\n",
            "Epoch: 462, train_loss: 0.487304, val_loss: 0.962639, val_accuracy: 0.751159, best_score: 0.759119\n",
            "Epoch: 463, train_loss: 0.618633, val_loss: 0.981506, val_accuracy: 0.754946, best_score: 0.759119\n",
            "Epoch: 464, train_loss: 0.475531, val_loss: 0.962521, val_accuracy: 0.753091, best_score: 0.759119\n",
            "Epoch: 465, train_loss: 0.645459, val_loss: 0.954696, val_accuracy: 0.753246, best_score: 0.759119\n",
            "Epoch: 466, train_loss: 0.623544, val_loss: 0.926282, val_accuracy: 0.755410, best_score: 0.759119\n",
            "Epoch: 467, train_loss: 0.569951, val_loss: 0.893015, val_accuracy: 0.756955, best_score: 0.759119\n",
            "Epoch: 468, train_loss: 0.558642, val_loss: 0.943777, val_accuracy: 0.750077, best_score: 0.759119\n",
            "Epoch: 469, train_loss: 0.584585, val_loss: 0.992265, val_accuracy: 0.751236, best_score: 0.759119\n",
            "Epoch: 470, train_loss: 0.623848, val_loss: 0.955932, val_accuracy: 0.756260, best_score: 0.759119\n",
            "Epoch: 471, train_loss: 0.601324, val_loss: 0.975186, val_accuracy: 0.755023, best_score: 0.759119\n",
            "Epoch: 472, train_loss: 0.510136, val_loss: 0.981612, val_accuracy: 0.753323, best_score: 0.759119\n",
            "Epoch: 473, train_loss: 0.740462, val_loss: 0.972164, val_accuracy: 0.753555, best_score: 0.759119\n",
            "Epoch: 474, train_loss: 0.544800, val_loss: 1.005590, val_accuracy: 0.751855, best_score: 0.759119\n",
            "Epoch: 475, train_loss: 0.503063, val_loss: 0.953434, val_accuracy: 0.752705, best_score: 0.759119\n",
            "Epoch: 476, train_loss: 0.594756, val_loss: 1.018565, val_accuracy: 0.748995, best_score: 0.759119\n",
            "Epoch: 477, train_loss: 0.645508, val_loss: 0.967478, val_accuracy: 0.755410, best_score: 0.759119\n",
            "Epoch: 478, train_loss: 0.466373, val_loss: 0.958196, val_accuracy: 0.751777, best_score: 0.759119\n",
            "Epoch: 479, train_loss: 0.821414, val_loss: 1.012846, val_accuracy: 0.751855, best_score: 0.759119\n",
            "Epoch: 480, train_loss: 0.625351, val_loss: 0.932003, val_accuracy: 0.752937, best_score: 0.759119\n",
            "Epoch: 481, train_loss: 0.654522, val_loss: 0.990403, val_accuracy: 0.754019, best_score: 0.759119\n",
            "Epoch: 482, train_loss: 0.417716, val_loss: 0.979490, val_accuracy: 0.756569, best_score: 0.759119\n",
            "Epoch: 483, train_loss: 0.564865, val_loss: 0.928621, val_accuracy: 0.752009, best_score: 0.759119\n",
            "Epoch: 484, train_loss: 0.757804, val_loss: 0.992274, val_accuracy: 0.756878, best_score: 0.759119\n",
            "Epoch: 485, train_loss: 0.415597, val_loss: 1.059321, val_accuracy: 0.751159, best_score: 0.759119\n",
            "Epoch: 486, train_loss: 0.620486, val_loss: 0.929232, val_accuracy: 0.755332, best_score: 0.759119\n",
            "Epoch: 487, train_loss: 0.533681, val_loss: 0.981431, val_accuracy: 0.757264, best_score: 0.759119\n",
            "Epoch: 488, train_loss: 0.570552, val_loss: 0.998355, val_accuracy: 0.756337, best_score: 0.759119\n",
            "Epoch: 489, train_loss: 0.540588, val_loss: 0.963072, val_accuracy: 0.753168, best_score: 0.759119\n",
            "Epoch: 490, train_loss: 0.519725, val_loss: 0.925502, val_accuracy: 0.754096, best_score: 0.759119\n",
            "Epoch: 491, train_loss: 0.621890, val_loss: 0.985047, val_accuracy: 0.756491, best_score: 0.759119\n",
            "Epoch: 492, train_loss: 0.768562, val_loss: 0.922617, val_accuracy: 0.757110, best_score: 0.759119\n",
            "Epoch: 493, train_loss: 0.591524, val_loss: 0.942389, val_accuracy: 0.756646, best_score: 0.759119\n",
            "Epoch: 494, train_loss: 0.611171, val_loss: 0.868284, val_accuracy: 0.756723, best_score: 0.759119\n",
            "Epoch: 495, train_loss: 0.725066, val_loss: 0.917831, val_accuracy: 0.755641, best_score: 0.759119\n",
            "Epoch: 496, train_loss: 0.555763, val_loss: 1.008410, val_accuracy: 0.753400, best_score: 0.759119\n",
            "Epoch: 497, train_loss: 0.600558, val_loss: 0.964724, val_accuracy: 0.749304, best_score: 0.759119\n",
            "Epoch: 498, train_loss: 0.576411, val_loss: 0.895827, val_accuracy: 0.753400, best_score: 0.759119\n",
            "Epoch: 499, train_loss: 0.762038, val_loss: 0.915630, val_accuracy: 0.754405, best_score: 0.759119\n",
            "Epoch: 500, train_loss: 0.620526, val_loss: 0.968146, val_accuracy: 0.754791, best_score: 0.759119\n",
            "Epoch: 501, train_loss: 1.042992, val_loss: 0.974160, val_accuracy: 0.748145, best_score: 0.759119\n",
            "Epoch: 502, train_loss: 0.524541, val_loss: 0.938091, val_accuracy: 0.751082, best_score: 0.759119\n",
            "Epoch: 503, train_loss: 0.626584, val_loss: 0.900866, val_accuracy: 0.757264, best_score: 0.759119\n",
            "Epoch: 504, train_loss: 0.821703, val_loss: 0.885769, val_accuracy: 0.757728, best_score: 0.759119\n",
            "Epoch: 505, train_loss: 0.509179, val_loss: 0.984286, val_accuracy: 0.753246, best_score: 0.759119\n",
            "Epoch: 506, train_loss: 0.799905, val_loss: 1.025640, val_accuracy: 0.749382, best_score: 0.759119\n",
            "Epoch: 507, train_loss: 0.611854, val_loss: 0.964963, val_accuracy: 0.749536, best_score: 0.759119\n",
            "Epoch: 508, train_loss: 0.525283, val_loss: 0.939680, val_accuracy: 0.753168, best_score: 0.759119\n",
            "Epoch: 509, train_loss: 0.564605, val_loss: 0.918458, val_accuracy: 0.754328, best_score: 0.759119\n",
            "Epoch: 510, train_loss: 0.586066, val_loss: 0.889936, val_accuracy: 0.759660, best_score: 0.759660\n",
            "Epoch: 511, train_loss: 0.606116, val_loss: 0.903225, val_accuracy: 0.753014, best_score: 0.759660\n",
            "Epoch: 512, train_loss: 0.682445, val_loss: 0.950689, val_accuracy: 0.752550, best_score: 0.759660\n",
            "Epoch: 513, train_loss: 0.553464, val_loss: 0.951609, val_accuracy: 0.750850, best_score: 0.759660\n",
            "Epoch: 514, train_loss: 0.550754, val_loss: 0.924052, val_accuracy: 0.754328, best_score: 0.759660\n",
            "Epoch: 515, train_loss: 0.506021, val_loss: 0.928667, val_accuracy: 0.755178, best_score: 0.759660\n",
            "Epoch: 516, train_loss: 0.684120, val_loss: 0.971964, val_accuracy: 0.750386, best_score: 0.759660\n",
            "Epoch: 517, train_loss: 0.631571, val_loss: 0.966131, val_accuracy: 0.754019, best_score: 0.759660\n",
            "Epoch: 518, train_loss: 0.751948, val_loss: 0.959943, val_accuracy: 0.753168, best_score: 0.759660\n",
            "Epoch: 519, train_loss: 0.450387, val_loss: 0.875658, val_accuracy: 0.756028, best_score: 0.759660\n",
            "Epoch: 520, train_loss: 0.594829, val_loss: 0.961779, val_accuracy: 0.755951, best_score: 0.759660\n",
            "Epoch: 521, train_loss: 0.625818, val_loss: 1.009629, val_accuracy: 0.750386, best_score: 0.759660\n",
            "Epoch: 522, train_loss: 0.706877, val_loss: 0.949805, val_accuracy: 0.752937, best_score: 0.759660\n",
            "Epoch: 523, train_loss: 0.908029, val_loss: 1.003842, val_accuracy: 0.758887, best_score: 0.759660\n",
            "Epoch: 524, train_loss: 0.613492, val_loss: 0.962581, val_accuracy: 0.757032, best_score: 0.759660\n",
            "Epoch: 525, train_loss: 0.570374, val_loss: 1.026579, val_accuracy: 0.747604, best_score: 0.759660\n",
            "Epoch: 526, train_loss: 0.517112, val_loss: 0.976232, val_accuracy: 0.749150, best_score: 0.759660\n",
            "Epoch: 527, train_loss: 0.703897, val_loss: 0.966276, val_accuracy: 0.743895, best_score: 0.759660\n",
            "Epoch: 528, train_loss: 0.537321, val_loss: 0.995022, val_accuracy: 0.753787, best_score: 0.759660\n",
            "Epoch: 529, train_loss: 0.653170, val_loss: 0.995658, val_accuracy: 0.757264, best_score: 0.759660\n",
            "Epoch: 530, train_loss: 0.814228, val_loss: 0.979893, val_accuracy: 0.758810, best_score: 0.759660\n",
            "Epoch: 531, train_loss: 0.625342, val_loss: 0.969687, val_accuracy: 0.753709, best_score: 0.759660\n",
            "Epoch: 532, train_loss: 0.370233, val_loss: 1.014480, val_accuracy: 0.752859, best_score: 0.759660\n",
            "Epoch: 533, train_loss: 0.633021, val_loss: 0.901505, val_accuracy: 0.759660, best_score: 0.759660\n",
            "Epoch: 534, train_loss: 0.632990, val_loss: 0.902684, val_accuracy: 0.756878, best_score: 0.759660\n",
            "Epoch: 535, train_loss: 0.495469, val_loss: 0.924642, val_accuracy: 0.751546, best_score: 0.759660\n",
            "Epoch: 536, train_loss: 0.493215, val_loss: 0.999719, val_accuracy: 0.752782, best_score: 0.759660\n",
            "Epoch: 537, train_loss: 0.713531, val_loss: 0.898591, val_accuracy: 0.755641, best_score: 0.759660\n",
            "Epoch: 538, train_loss: 0.728515, val_loss: 0.894720, val_accuracy: 0.754328, best_score: 0.759660\n",
            "Epoch: 539, train_loss: 0.499428, val_loss: 0.865717, val_accuracy: 0.756028, best_score: 0.759660\n",
            "Epoch: 540, train_loss: 0.586721, val_loss: 0.961947, val_accuracy: 0.751700, best_score: 0.759660\n",
            "Epoch: 541, train_loss: 0.826059, val_loss: 0.919511, val_accuracy: 0.754250, best_score: 0.759660\n",
            "Epoch: 542, train_loss: 0.511741, val_loss: 0.980550, val_accuracy: 0.756723, best_score: 0.759660\n",
            "Epoch: 543, train_loss: 0.624936, val_loss: 0.941906, val_accuracy: 0.747682, best_score: 0.759660\n",
            "Epoch: 544, train_loss: 0.608714, val_loss: 0.972373, val_accuracy: 0.752241, best_score: 0.759660\n",
            "Epoch: 545, train_loss: 0.521983, val_loss: 0.934407, val_accuracy: 0.753323, best_score: 0.759660\n",
            "Epoch: 546, train_loss: 0.877515, val_loss: 0.910247, val_accuracy: 0.756801, best_score: 0.759660\n",
            "Epoch: 547, train_loss: 0.664318, val_loss: 0.977197, val_accuracy: 0.753941, best_score: 0.759660\n",
            "Epoch: 548, train_loss: 0.660765, val_loss: 0.935570, val_accuracy: 0.753323, best_score: 0.759660\n",
            "Epoch: 549, train_loss: 0.655847, val_loss: 0.961370, val_accuracy: 0.756414, best_score: 0.759660\n",
            "Epoch: 550, train_loss: 0.983986, val_loss: 0.978013, val_accuracy: 0.750000, best_score: 0.759660\n",
            "Epoch: 551, train_loss: 0.484276, val_loss: 1.012268, val_accuracy: 0.748068, best_score: 0.759660\n",
            "Epoch: 552, train_loss: 0.630301, val_loss: 0.933768, val_accuracy: 0.753400, best_score: 0.759660\n",
            "Epoch: 553, train_loss: 0.558556, val_loss: 0.971186, val_accuracy: 0.751623, best_score: 0.759660\n",
            "Epoch: 554, train_loss: 0.510181, val_loss: 0.941965, val_accuracy: 0.757651, best_score: 0.759660\n",
            "Epoch: 555, train_loss: 0.635940, val_loss: 1.022786, val_accuracy: 0.750232, best_score: 0.759660\n",
            "Epoch: 556, train_loss: 0.566768, val_loss: 1.031692, val_accuracy: 0.754714, best_score: 0.759660\n",
            "Epoch: 557, train_loss: 0.643076, val_loss: 0.947521, val_accuracy: 0.752087, best_score: 0.759660\n",
            "Epoch: 558, train_loss: 0.511854, val_loss: 0.998682, val_accuracy: 0.753400, best_score: 0.759660\n",
            "Epoch: 559, train_loss: 0.591927, val_loss: 1.016929, val_accuracy: 0.751159, best_score: 0.759660\n",
            "Epoch: 560, train_loss: 0.651146, val_loss: 1.005147, val_accuracy: 0.748609, best_score: 0.759660\n",
            "Epoch: 561, train_loss: 0.720077, val_loss: 0.942619, val_accuracy: 0.758733, best_score: 0.759660\n",
            "Epoch: 562, train_loss: 0.576224, val_loss: 0.943675, val_accuracy: 0.755873, best_score: 0.759660\n",
            "Epoch: 563, train_loss: 0.572214, val_loss: 0.928723, val_accuracy: 0.753400, best_score: 0.759660\n",
            "Epoch: 564, train_loss: 0.743748, val_loss: 0.969072, val_accuracy: 0.755719, best_score: 0.759660\n",
            "Epoch: 565, train_loss: 0.562971, val_loss: 1.004630, val_accuracy: 0.751623, best_score: 0.759660\n",
            "Epoch: 566, train_loss: 0.539671, val_loss: 1.015509, val_accuracy: 0.750386, best_score: 0.759660\n",
            "Epoch: 567, train_loss: 0.491003, val_loss: 0.957917, val_accuracy: 0.755410, best_score: 0.759660\n",
            "Epoch: 568, train_loss: 0.631399, val_loss: 0.918150, val_accuracy: 0.758655, best_score: 0.759660\n",
            "Epoch: 569, train_loss: 0.575521, val_loss: 0.973496, val_accuracy: 0.751391, best_score: 0.759660\n",
            "Epoch: 570, train_loss: 0.521069, val_loss: 0.950501, val_accuracy: 0.751623, best_score: 0.759660\n",
            "Epoch: 571, train_loss: 0.405228, val_loss: 0.922266, val_accuracy: 0.756414, best_score: 0.759660\n",
            "Epoch: 572, train_loss: 0.541055, val_loss: 0.966402, val_accuracy: 0.754637, best_score: 0.759660\n",
            "Epoch: 573, train_loss: 0.501635, val_loss: 0.935289, val_accuracy: 0.751855, best_score: 0.759660\n",
            "Epoch: 574, train_loss: 0.487210, val_loss: 0.924848, val_accuracy: 0.756646, best_score: 0.759660\n",
            "Epoch: 575, train_loss: 0.657577, val_loss: 0.902122, val_accuracy: 0.758114, best_score: 0.759660\n",
            "Epoch: 576, train_loss: 0.519166, val_loss: 0.980437, val_accuracy: 0.750232, best_score: 0.759660\n",
            "Epoch: 577, train_loss: 0.679586, val_loss: 0.985739, val_accuracy: 0.750927, best_score: 0.759660\n",
            "Epoch: 578, train_loss: 0.755208, val_loss: 0.988164, val_accuracy: 0.750386, best_score: 0.759660\n",
            "Epoch: 579, train_loss: 0.585497, val_loss: 0.966379, val_accuracy: 0.754328, best_score: 0.759660\n",
            "Epoch: 580, train_loss: 0.498593, val_loss: 1.044775, val_accuracy: 0.749923, best_score: 0.759660\n",
            "Epoch: 581, train_loss: 0.779041, val_loss: 0.954074, val_accuracy: 0.754250, best_score: 0.759660\n",
            "Epoch: 582, train_loss: 0.691183, val_loss: 0.999267, val_accuracy: 0.754019, best_score: 0.759660\n",
            "Epoch: 583, train_loss: 0.700665, val_loss: 1.000360, val_accuracy: 0.753941, best_score: 0.759660\n",
            "Epoch: 584, train_loss: 0.611942, val_loss: 0.985779, val_accuracy: 0.756182, best_score: 0.759660\n",
            "Epoch: 585, train_loss: 0.667631, val_loss: 0.950053, val_accuracy: 0.758346, best_score: 0.759660\n",
            "Epoch: 586, train_loss: 0.555609, val_loss: 1.006874, val_accuracy: 0.756028, best_score: 0.759660\n",
            "Epoch: 587, train_loss: 0.949598, val_loss: 1.017711, val_accuracy: 0.757419, best_score: 0.759660\n",
            "Epoch: 588, train_loss: 0.391744, val_loss: 1.047625, val_accuracy: 0.749459, best_score: 0.759660\n",
            "Epoch: 589, train_loss: 0.583183, val_loss: 0.967438, val_accuracy: 0.755487, best_score: 0.759660\n",
            "Epoch: 590, train_loss: 0.596464, val_loss: 0.960656, val_accuracy: 0.755255, best_score: 0.759660\n",
            "Epoch: 591, train_loss: 0.515767, val_loss: 0.946105, val_accuracy: 0.752550, best_score: 0.759660\n",
            "Epoch: 592, train_loss: 0.513017, val_loss: 0.962595, val_accuracy: 0.752396, best_score: 0.759660\n",
            "Epoch: 593, train_loss: 0.761549, val_loss: 0.920356, val_accuracy: 0.756028, best_score: 0.759660\n",
            "Epoch: 594, train_loss: 0.728943, val_loss: 0.933502, val_accuracy: 0.752937, best_score: 0.759660\n",
            "Epoch: 595, train_loss: 0.712643, val_loss: 1.034237, val_accuracy: 0.757032, best_score: 0.759660\n",
            "Epoch: 596, train_loss: 0.511497, val_loss: 0.985108, val_accuracy: 0.755255, best_score: 0.759660\n",
            "Epoch: 597, train_loss: 0.545989, val_loss: 1.003058, val_accuracy: 0.752396, best_score: 0.759660\n",
            "Epoch: 598, train_loss: 0.617673, val_loss: 1.082092, val_accuracy: 0.750618, best_score: 0.759660\n",
            "Epoch: 599, train_loss: 0.695374, val_loss: 0.973886, val_accuracy: 0.754869, best_score: 0.759660\n",
            "Epoch: 600, train_loss: 0.532044, val_loss: 1.047110, val_accuracy: 0.753246, best_score: 0.759660\n",
            "Epoch: 601, train_loss: 0.581241, val_loss: 1.006303, val_accuracy: 0.753246, best_score: 0.759660\n",
            "Epoch: 602, train_loss: 0.663226, val_loss: 1.081566, val_accuracy: 0.751236, best_score: 0.759660\n",
            "Epoch: 603, train_loss: 0.410577, val_loss: 1.041775, val_accuracy: 0.754791, best_score: 0.759660\n",
            "Epoch: 604, train_loss: 0.465482, val_loss: 1.066658, val_accuracy: 0.750927, best_score: 0.759660\n",
            "Epoch: 605, train_loss: 0.685106, val_loss: 1.002762, val_accuracy: 0.748532, best_score: 0.759660\n",
            "Epoch: 606, train_loss: 0.693624, val_loss: 0.944291, val_accuracy: 0.759505, best_score: 0.759660\n",
            "Epoch: 607, train_loss: 0.396205, val_loss: 1.009510, val_accuracy: 0.754791, best_score: 0.759660\n",
            "Epoch: 608, train_loss: 0.488429, val_loss: 0.957867, val_accuracy: 0.755873, best_score: 0.759660\n",
            "Epoch: 609, train_loss: 0.682553, val_loss: 1.005338, val_accuracy: 0.754482, best_score: 0.759660\n",
            "Epoch: 610, train_loss: 0.571193, val_loss: 0.941492, val_accuracy: 0.755719, best_score: 0.759660\n",
            "Epoch: 611, train_loss: 0.624992, val_loss: 0.950444, val_accuracy: 0.760896, best_score: 0.760896\n",
            "Epoch: 612, train_loss: 0.526535, val_loss: 1.010552, val_accuracy: 0.754869, best_score: 0.760896\n",
            "Epoch: 613, train_loss: 0.617442, val_loss: 1.044431, val_accuracy: 0.755796, best_score: 0.760896\n",
            "Epoch: 614, train_loss: 0.561966, val_loss: 0.998353, val_accuracy: 0.755178, best_score: 0.760896\n",
            "Epoch: 615, train_loss: 0.488242, val_loss: 0.975892, val_accuracy: 0.755951, best_score: 0.760896\n",
            "Epoch: 616, train_loss: 0.615122, val_loss: 1.005975, val_accuracy: 0.752859, best_score: 0.760896\n",
            "Epoch: 617, train_loss: 0.772041, val_loss: 0.997211, val_accuracy: 0.752550, best_score: 0.760896\n",
            "Epoch: 618, train_loss: 0.568312, val_loss: 0.992328, val_accuracy: 0.756491, best_score: 0.760896\n",
            "Epoch: 619, train_loss: 0.578549, val_loss: 0.931792, val_accuracy: 0.756569, best_score: 0.760896\n",
            "Epoch: 620, train_loss: 0.732575, val_loss: 1.005958, val_accuracy: 0.747604, best_score: 0.760896\n",
            "Epoch: 621, train_loss: 0.571703, val_loss: 1.011001, val_accuracy: 0.753400, best_score: 0.760896\n",
            "Epoch: 622, train_loss: 0.618291, val_loss: 0.934587, val_accuracy: 0.754405, best_score: 0.760896\n",
            "Epoch: 623, train_loss: 0.772843, val_loss: 0.974670, val_accuracy: 0.754328, best_score: 0.760896\n",
            "Epoch: 624, train_loss: 0.513208, val_loss: 0.934002, val_accuracy: 0.756801, best_score: 0.760896\n",
            "Epoch: 625, train_loss: 0.635912, val_loss: 0.961650, val_accuracy: 0.754946, best_score: 0.760896\n",
            "Epoch: 626, train_loss: 0.488694, val_loss: 0.993949, val_accuracy: 0.753787, best_score: 0.760896\n",
            "Epoch: 627, train_loss: 0.721302, val_loss: 0.992682, val_accuracy: 0.749073, best_score: 0.760896\n",
            "Epoch: 628, train_loss: 0.733260, val_loss: 1.025693, val_accuracy: 0.753864, best_score: 0.760896\n",
            "Epoch: 629, train_loss: 0.485444, val_loss: 0.970556, val_accuracy: 0.755100, best_score: 0.760896\n",
            "Epoch: 630, train_loss: 0.568257, val_loss: 0.990893, val_accuracy: 0.754019, best_score: 0.760896\n",
            "Epoch: 631, train_loss: 0.802920, val_loss: 0.966766, val_accuracy: 0.755951, best_score: 0.760896\n",
            "Epoch: 632, train_loss: 0.419585, val_loss: 1.054689, val_accuracy: 0.752705, best_score: 0.760896\n",
            "Epoch: 633, train_loss: 0.533057, val_loss: 0.962586, val_accuracy: 0.753323, best_score: 0.760896\n",
            "Epoch: 634, train_loss: 0.575874, val_loss: 1.010082, val_accuracy: 0.753941, best_score: 0.760896\n",
            "Epoch: 635, train_loss: 0.557860, val_loss: 1.031210, val_accuracy: 0.755564, best_score: 0.760896\n",
            "Epoch: 636, train_loss: 0.605835, val_loss: 0.943467, val_accuracy: 0.754714, best_score: 0.760896\n",
            "Epoch: 637, train_loss: 0.847115, val_loss: 1.047029, val_accuracy: 0.748686, best_score: 0.760896\n",
            "Epoch: 638, train_loss: 0.701619, val_loss: 0.985293, val_accuracy: 0.752705, best_score: 0.760896\n",
            "Epoch: 639, train_loss: 0.491606, val_loss: 0.953735, val_accuracy: 0.752009, best_score: 0.760896\n",
            "Epoch: 640, train_loss: 0.609316, val_loss: 0.981244, val_accuracy: 0.753787, best_score: 0.760896\n",
            "Epoch: 641, train_loss: 0.636886, val_loss: 1.005380, val_accuracy: 0.757187, best_score: 0.760896\n",
            "Epoch: 642, train_loss: 0.614712, val_loss: 0.989366, val_accuracy: 0.759505, best_score: 0.760896\n",
            "Epoch: 643, train_loss: 0.599795, val_loss: 0.961101, val_accuracy: 0.753787, best_score: 0.760896\n",
            "Epoch: 644, train_loss: 0.510717, val_loss: 0.938564, val_accuracy: 0.756646, best_score: 0.760896\n",
            "Epoch: 645, train_loss: 0.603617, val_loss: 1.025504, val_accuracy: 0.757573, best_score: 0.760896\n",
            "Epoch: 646, train_loss: 0.605042, val_loss: 1.050898, val_accuracy: 0.751700, best_score: 0.760896\n",
            "Epoch: 647, train_loss: 0.721072, val_loss: 0.995923, val_accuracy: 0.754946, best_score: 0.760896\n",
            "Epoch: 648, train_loss: 0.567582, val_loss: 1.030538, val_accuracy: 0.755487, best_score: 0.760896\n",
            "Epoch: 649, train_loss: 0.481453, val_loss: 0.955743, val_accuracy: 0.756260, best_score: 0.760896\n",
            "Epoch: 650, train_loss: 0.717965, val_loss: 1.002331, val_accuracy: 0.749536, best_score: 0.760896\n",
            "Epoch: 651, train_loss: 0.484091, val_loss: 1.053825, val_accuracy: 0.753246, best_score: 0.760896\n",
            "Epoch: 652, train_loss: 0.478163, val_loss: 1.027763, val_accuracy: 0.757960, best_score: 0.760896\n",
            "Epoch: 653, train_loss: 0.560513, val_loss: 1.049712, val_accuracy: 0.751005, best_score: 0.760896\n",
            "Epoch: 654, train_loss: 0.535223, val_loss: 1.025046, val_accuracy: 0.753014, best_score: 0.760896\n",
            "Epoch: 655, train_loss: 0.424232, val_loss: 0.956750, val_accuracy: 0.754250, best_score: 0.760896\n",
            "Epoch: 656, train_loss: 0.551667, val_loss: 1.005330, val_accuracy: 0.756028, best_score: 0.760896\n",
            "Epoch: 657, train_loss: 0.619540, val_loss: 0.973621, val_accuracy: 0.751777, best_score: 0.760896\n",
            "Epoch: 658, train_loss: 0.548736, val_loss: 0.962251, val_accuracy: 0.759737, best_score: 0.760896\n",
            "Epoch: 659, train_loss: 0.685839, val_loss: 0.936359, val_accuracy: 0.749382, best_score: 0.760896\n",
            "Epoch: 660, train_loss: 0.452008, val_loss: 0.941661, val_accuracy: 0.757264, best_score: 0.760896\n",
            "Epoch: 661, train_loss: 0.387239, val_loss: 0.971037, val_accuracy: 0.751777, best_score: 0.760896\n",
            "Epoch: 662, train_loss: 0.624586, val_loss: 0.975781, val_accuracy: 0.752937, best_score: 0.760896\n",
            "Epoch: 663, train_loss: 0.747717, val_loss: 0.957958, val_accuracy: 0.750618, best_score: 0.760896\n",
            "Epoch: 664, train_loss: 0.722490, val_loss: 0.959200, val_accuracy: 0.752087, best_score: 0.760896\n",
            "Epoch: 665, train_loss: 0.566520, val_loss: 0.933976, val_accuracy: 0.747450, best_score: 0.760896\n",
            "Epoch: 666, train_loss: 0.715049, val_loss: 0.930212, val_accuracy: 0.752628, best_score: 0.760896\n",
            "Epoch: 667, train_loss: 0.641776, val_loss: 1.000543, val_accuracy: 0.754482, best_score: 0.760896\n",
            "Epoch: 668, train_loss: 0.531280, val_loss: 0.933534, val_accuracy: 0.758887, best_score: 0.760896\n",
            "Epoch: 669, train_loss: 0.637981, val_loss: 0.983281, val_accuracy: 0.750232, best_score: 0.760896\n",
            "Epoch: 670, train_loss: 0.820121, val_loss: 0.885695, val_accuracy: 0.758655, best_score: 0.760896\n",
            "Epoch: 671, train_loss: 0.679939, val_loss: 0.997312, val_accuracy: 0.755796, best_score: 0.760896\n",
            "Epoch: 672, train_loss: 0.509467, val_loss: 0.909394, val_accuracy: 0.755332, best_score: 0.760896\n",
            "Epoch: 673, train_loss: 0.572954, val_loss: 0.996672, val_accuracy: 0.751236, best_score: 0.760896\n",
            "Epoch: 674, train_loss: 0.713510, val_loss: 0.952071, val_accuracy: 0.751314, best_score: 0.760896\n",
            "Epoch: 675, train_loss: 0.642967, val_loss: 1.037223, val_accuracy: 0.751855, best_score: 0.760896\n",
            "Epoch: 676, train_loss: 0.589645, val_loss: 0.934293, val_accuracy: 0.754637, best_score: 0.760896\n",
            "Epoch: 677, train_loss: 0.563606, val_loss: 0.934949, val_accuracy: 0.754250, best_score: 0.760896\n",
            "Epoch: 678, train_loss: 0.599574, val_loss: 0.993001, val_accuracy: 0.748068, best_score: 0.760896\n",
            "Epoch: 679, train_loss: 0.526972, val_loss: 0.978861, val_accuracy: 0.751236, best_score: 0.760896\n",
            "Epoch: 680, train_loss: 0.726017, val_loss: 0.979284, val_accuracy: 0.758578, best_score: 0.760896\n",
            "Epoch: 681, train_loss: 0.696160, val_loss: 0.967165, val_accuracy: 0.758037, best_score: 0.760896\n",
            "Epoch: 682, train_loss: 0.689796, val_loss: 0.986273, val_accuracy: 0.756646, best_score: 0.760896\n",
            "Epoch: 683, train_loss: 0.506397, val_loss: 1.062918, val_accuracy: 0.750000, best_score: 0.760896\n",
            "Epoch: 684, train_loss: 0.519117, val_loss: 0.988454, val_accuracy: 0.755178, best_score: 0.760896\n",
            "Epoch: 685, train_loss: 0.619169, val_loss: 0.938260, val_accuracy: 0.758810, best_score: 0.760896\n",
            "Epoch: 686, train_loss: 0.639579, val_loss: 0.914817, val_accuracy: 0.760433, best_score: 0.760896\n",
            "Epoch: 687, train_loss: 0.693927, val_loss: 1.001515, val_accuracy: 0.755178, best_score: 0.760896\n",
            "Epoch: 688, train_loss: 0.846623, val_loss: 0.946407, val_accuracy: 0.753555, best_score: 0.760896\n",
            "Epoch: 689, train_loss: 0.662988, val_loss: 1.046628, val_accuracy: 0.748686, best_score: 0.760896\n",
            "Epoch: 690, train_loss: 0.468465, val_loss: 0.984239, val_accuracy: 0.750618, best_score: 0.760896\n",
            "Epoch: 691, train_loss: 0.532413, val_loss: 0.962791, val_accuracy: 0.753632, best_score: 0.760896\n",
            "Epoch: 692, train_loss: 0.543526, val_loss: 0.953838, val_accuracy: 0.755100, best_score: 0.760896\n",
            "Epoch: 693, train_loss: 0.768980, val_loss: 0.984338, val_accuracy: 0.760046, best_score: 0.760896\n",
            "Epoch: 694, train_loss: 0.748891, val_loss: 0.969143, val_accuracy: 0.754791, best_score: 0.760896\n",
            "Epoch: 695, train_loss: 0.581064, val_loss: 1.029930, val_accuracy: 0.752937, best_score: 0.760896\n",
            "Epoch: 696, train_loss: 0.683282, val_loss: 0.969924, val_accuracy: 0.756569, best_score: 0.760896\n",
            "Epoch: 697, train_loss: 0.519291, val_loss: 0.953577, val_accuracy: 0.756646, best_score: 0.760896\n",
            "Epoch: 698, train_loss: 0.671451, val_loss: 0.947878, val_accuracy: 0.754173, best_score: 0.760896\n",
            "Epoch: 699, train_loss: 0.671637, val_loss: 1.069042, val_accuracy: 0.753091, best_score: 0.760896\n",
            "Epoch: 700, train_loss: 0.493333, val_loss: 0.969966, val_accuracy: 0.757032, best_score: 0.760896\n",
            "Epoch: 701, train_loss: 0.607870, val_loss: 0.938695, val_accuracy: 0.755023, best_score: 0.760896\n",
            "Epoch: 702, train_loss: 0.605738, val_loss: 0.903164, val_accuracy: 0.750541, best_score: 0.760896\n",
            "Epoch: 703, train_loss: 0.560772, val_loss: 0.941798, val_accuracy: 0.753709, best_score: 0.760896\n",
            "Epoch: 704, train_loss: 0.636460, val_loss: 0.909318, val_accuracy: 0.752705, best_score: 0.760896\n",
            "Epoch: 705, train_loss: 0.630124, val_loss: 0.943275, val_accuracy: 0.755719, best_score: 0.760896\n",
            "Epoch: 706, train_loss: 0.677971, val_loss: 0.939819, val_accuracy: 0.749614, best_score: 0.760896\n",
            "Epoch: 707, train_loss: 0.530271, val_loss: 0.961149, val_accuracy: 0.753555, best_score: 0.760896\n",
            "Epoch: 708, train_loss: 0.659408, val_loss: 0.991763, val_accuracy: 0.754173, best_score: 0.760896\n",
            "Epoch: 709, train_loss: 0.662515, val_loss: 0.918213, val_accuracy: 0.756801, best_score: 0.760896\n",
            "Epoch: 710, train_loss: 0.458107, val_loss: 0.970794, val_accuracy: 0.753246, best_score: 0.760896\n",
            "Epoch: 711, train_loss: 0.660649, val_loss: 0.979833, val_accuracy: 0.751546, best_score: 0.760896\n",
            "Epoch: 712, train_loss: 0.763557, val_loss: 0.970904, val_accuracy: 0.756569, best_score: 0.760896\n",
            "Epoch: 713, train_loss: 0.496555, val_loss: 0.969215, val_accuracy: 0.757728, best_score: 0.760896\n",
            "Epoch: 714, train_loss: 0.697452, val_loss: 0.957872, val_accuracy: 0.751777, best_score: 0.760896\n",
            "Epoch: 715, train_loss: 0.769550, val_loss: 0.930969, val_accuracy: 0.752164, best_score: 0.760896\n",
            "Epoch: 716, train_loss: 0.506420, val_loss: 1.004716, val_accuracy: 0.755951, best_score: 0.760896\n",
            "Epoch: 717, train_loss: 0.665407, val_loss: 1.017262, val_accuracy: 0.755178, best_score: 0.760896\n",
            "Epoch: 718, train_loss: 0.640783, val_loss: 0.922888, val_accuracy: 0.755410, best_score: 0.760896\n",
            "Epoch: 719, train_loss: 0.683430, val_loss: 1.017567, val_accuracy: 0.747836, best_score: 0.760896\n",
            "Epoch: 720, train_loss: 0.577941, val_loss: 0.934218, val_accuracy: 0.755487, best_score: 0.760896\n",
            "Epoch: 721, train_loss: 0.495345, val_loss: 1.022444, val_accuracy: 0.757573, best_score: 0.760896\n",
            "Epoch: 722, train_loss: 0.487352, val_loss: 1.016530, val_accuracy: 0.751546, best_score: 0.760896\n",
            "Epoch: 723, train_loss: 0.670296, val_loss: 0.968172, val_accuracy: 0.752241, best_score: 0.760896\n",
            "Epoch: 724, train_loss: 0.673235, val_loss: 0.896546, val_accuracy: 0.754869, best_score: 0.760896\n",
            "Epoch: 725, train_loss: 0.606391, val_loss: 0.949580, val_accuracy: 0.750850, best_score: 0.760896\n",
            "Epoch: 726, train_loss: 0.690940, val_loss: 0.903850, val_accuracy: 0.752782, best_score: 0.760896\n",
            "Epoch: 727, train_loss: 0.450704, val_loss: 1.002190, val_accuracy: 0.748609, best_score: 0.760896\n",
            "Epoch: 728, train_loss: 0.622607, val_loss: 1.016413, val_accuracy: 0.747604, best_score: 0.760896\n",
            "Epoch: 729, train_loss: 0.674011, val_loss: 0.967806, val_accuracy: 0.749382, best_score: 0.760896\n",
            "Epoch: 730, train_loss: 0.549107, val_loss: 1.020857, val_accuracy: 0.754250, best_score: 0.760896\n",
            "Epoch: 731, train_loss: 0.706388, val_loss: 0.966915, val_accuracy: 0.752164, best_score: 0.760896\n",
            "Epoch: 732, train_loss: 0.473000, val_loss: 0.933662, val_accuracy: 0.757573, best_score: 0.760896\n",
            "Epoch: 733, train_loss: 0.724761, val_loss: 0.957250, val_accuracy: 0.753787, best_score: 0.760896\n",
            "Epoch: 734, train_loss: 0.680105, val_loss: 0.946467, val_accuracy: 0.754560, best_score: 0.760896\n",
            "Epoch: 735, train_loss: 0.471454, val_loss: 0.960441, val_accuracy: 0.754405, best_score: 0.760896\n",
            "Epoch: 736, train_loss: 0.770099, val_loss: 0.966377, val_accuracy: 0.751159, best_score: 0.760896\n",
            "Epoch: 737, train_loss: 0.813247, val_loss: 1.023990, val_accuracy: 0.753787, best_score: 0.760896\n",
            "Epoch: 738, train_loss: 0.786517, val_loss: 0.991475, val_accuracy: 0.757419, best_score: 0.760896\n",
            "Epoch: 739, train_loss: 0.588568, val_loss: 0.988936, val_accuracy: 0.753478, best_score: 0.760896\n",
            "Epoch: 740, train_loss: 0.586060, val_loss: 1.001152, val_accuracy: 0.755873, best_score: 0.760896\n",
            "Epoch: 741, train_loss: 0.475571, val_loss: 0.964804, val_accuracy: 0.753709, best_score: 0.760896\n",
            "Epoch: 742, train_loss: 0.528302, val_loss: 0.971854, val_accuracy: 0.749923, best_score: 0.760896\n",
            "Epoch: 743, train_loss: 1.049963, val_loss: 1.010485, val_accuracy: 0.757110, best_score: 0.760896\n",
            "Epoch: 744, train_loss: 0.455037, val_loss: 0.966675, val_accuracy: 0.755951, best_score: 0.760896\n",
            "Epoch: 745, train_loss: 0.533985, val_loss: 1.014128, val_accuracy: 0.754405, best_score: 0.760896\n",
            "Epoch: 746, train_loss: 0.833510, val_loss: 1.042732, val_accuracy: 0.751932, best_score: 0.760896\n",
            "Epoch: 747, train_loss: 0.543183, val_loss: 1.044034, val_accuracy: 0.749768, best_score: 0.760896\n",
            "Epoch: 748, train_loss: 0.696119, val_loss: 0.979206, val_accuracy: 0.756182, best_score: 0.760896\n",
            "Epoch: 749, train_loss: 0.554437, val_loss: 1.048067, val_accuracy: 0.751700, best_score: 0.760896\n",
            "Epoch: 750, train_loss: 0.747495, val_loss: 1.036401, val_accuracy: 0.754637, best_score: 0.760896\n",
            "Epoch: 751, train_loss: 0.630746, val_loss: 1.018770, val_accuracy: 0.752087, best_score: 0.760896\n",
            "Epoch: 752, train_loss: 0.566471, val_loss: 0.878848, val_accuracy: 0.759428, best_score: 0.760896\n",
            "Epoch: 753, train_loss: 0.838237, val_loss: 0.925131, val_accuracy: 0.755023, best_score: 0.760896\n",
            "Epoch: 754, train_loss: 0.830648, val_loss: 0.956283, val_accuracy: 0.760433, best_score: 0.760896\n",
            "Epoch: 755, train_loss: 0.570655, val_loss: 0.988295, val_accuracy: 0.755873, best_score: 0.760896\n",
            "Epoch: 756, train_loss: 0.424951, val_loss: 0.938240, val_accuracy: 0.758037, best_score: 0.760896\n",
            "Epoch: 757, train_loss: 0.605498, val_loss: 1.020852, val_accuracy: 0.751314, best_score: 0.760896\n",
            "Epoch: 758, train_loss: 0.807225, val_loss: 0.968372, val_accuracy: 0.754096, best_score: 0.760896\n",
            "Epoch: 759, train_loss: 0.731437, val_loss: 0.987001, val_accuracy: 0.753864, best_score: 0.760896\n",
            "Epoch: 760, train_loss: 0.448978, val_loss: 0.923085, val_accuracy: 0.755641, best_score: 0.760896\n",
            "Epoch: 761, train_loss: 0.941684, val_loss: 1.073241, val_accuracy: 0.752859, best_score: 0.760896\n",
            "Epoch: 762, train_loss: 0.652687, val_loss: 1.047806, val_accuracy: 0.751546, best_score: 0.760896\n",
            "Epoch: 763, train_loss: 0.403724, val_loss: 0.998100, val_accuracy: 0.749768, best_score: 0.760896\n",
            "Epoch: 764, train_loss: 0.599288, val_loss: 0.958948, val_accuracy: 0.753709, best_score: 0.760896\n",
            "Epoch: 765, train_loss: 0.479994, val_loss: 0.938889, val_accuracy: 0.753864, best_score: 0.760896\n",
            "Epoch: 766, train_loss: 0.587444, val_loss: 0.873337, val_accuracy: 0.757110, best_score: 0.760896\n",
            "Epoch: 767, train_loss: 0.578882, val_loss: 0.939175, val_accuracy: 0.745672, best_score: 0.760896\n",
            "Epoch: 768, train_loss: 0.535805, val_loss: 0.855920, val_accuracy: 0.752164, best_score: 0.760896\n",
            "Epoch: 769, train_loss: 0.366735, val_loss: 1.004045, val_accuracy: 0.755641, best_score: 0.760896\n",
            "Epoch: 770, train_loss: 0.723345, val_loss: 0.933743, val_accuracy: 0.754560, best_score: 0.760896\n",
            "Epoch: 771, train_loss: 0.517922, val_loss: 0.960072, val_accuracy: 0.753632, best_score: 0.760896\n",
            "Epoch: 772, train_loss: 0.470347, val_loss: 0.908484, val_accuracy: 0.754405, best_score: 0.760896\n",
            "Epoch: 773, train_loss: 0.530514, val_loss: 0.997806, val_accuracy: 0.755719, best_score: 0.760896\n",
            "Epoch: 774, train_loss: 0.780971, val_loss: 0.973560, val_accuracy: 0.752628, best_score: 0.760896\n",
            "Epoch: 775, train_loss: 0.606442, val_loss: 1.020606, val_accuracy: 0.754637, best_score: 0.760896\n",
            "Epoch: 776, train_loss: 0.577564, val_loss: 0.892167, val_accuracy: 0.760587, best_score: 0.760896\n",
            "Epoch: 777, train_loss: 0.410227, val_loss: 0.983713, val_accuracy: 0.746986, best_score: 0.760896\n",
            "Epoch: 778, train_loss: 0.460306, val_loss: 1.017374, val_accuracy: 0.754096, best_score: 0.760896\n",
            "Epoch: 779, train_loss: 0.698771, val_loss: 0.889688, val_accuracy: 0.760433, best_score: 0.760896\n",
            "Epoch: 780, train_loss: 0.580198, val_loss: 0.999724, val_accuracy: 0.756646, best_score: 0.760896\n",
            "Epoch: 781, train_loss: 0.440298, val_loss: 0.978712, val_accuracy: 0.755951, best_score: 0.760896\n",
            "Epoch: 782, train_loss: 0.802266, val_loss: 0.964929, val_accuracy: 0.754946, best_score: 0.760896\n",
            "Epoch: 783, train_loss: 0.518726, val_loss: 0.983713, val_accuracy: 0.753323, best_score: 0.760896\n",
            "Epoch: 784, train_loss: 0.605912, val_loss: 0.978468, val_accuracy: 0.753400, best_score: 0.760896\n",
            "Epoch: 785, train_loss: 0.688653, val_loss: 1.041363, val_accuracy: 0.755023, best_score: 0.760896\n",
            "Epoch: 786, train_loss: 0.689645, val_loss: 0.969177, val_accuracy: 0.756260, best_score: 0.760896\n",
            "Epoch: 787, train_loss: 0.625273, val_loss: 0.980048, val_accuracy: 0.754560, best_score: 0.760896\n",
            "Epoch: 788, train_loss: 0.700528, val_loss: 0.973914, val_accuracy: 0.754173, best_score: 0.760896\n",
            "Epoch: 789, train_loss: 0.577482, val_loss: 0.921722, val_accuracy: 0.754019, best_score: 0.760896\n",
            "Epoch: 790, train_loss: 0.708434, val_loss: 0.903204, val_accuracy: 0.757651, best_score: 0.760896\n",
            "Epoch: 791, train_loss: 0.528121, val_loss: 0.883284, val_accuracy: 0.753168, best_score: 0.760896\n",
            "Epoch: 792, train_loss: 0.747495, val_loss: 0.897030, val_accuracy: 0.756955, best_score: 0.760896\n",
            "Epoch: 793, train_loss: 0.483926, val_loss: 0.920298, val_accuracy: 0.752937, best_score: 0.760896\n",
            "Epoch: 794, train_loss: 0.659454, val_loss: 0.983107, val_accuracy: 0.753014, best_score: 0.760896\n",
            "Epoch: 795, train_loss: 0.704976, val_loss: 0.883097, val_accuracy: 0.755873, best_score: 0.760896\n",
            "Epoch: 796, train_loss: 0.491630, val_loss: 0.939031, val_accuracy: 0.753632, best_score: 0.760896\n",
            "Epoch: 797, train_loss: 0.571804, val_loss: 0.959122, val_accuracy: 0.758423, best_score: 0.760896\n",
            "Epoch: 798, train_loss: 0.526106, val_loss: 0.983817, val_accuracy: 0.754560, best_score: 0.760896\n",
            "Epoch: 799, train_loss: 0.487229, val_loss: 1.044746, val_accuracy: 0.754096, best_score: 0.760896\n",
            "Epoch: 800, train_loss: 0.652019, val_loss: 0.984660, val_accuracy: 0.751623, best_score: 0.760896\n",
            "Epoch: 801, train_loss: 0.634293, val_loss: 0.889786, val_accuracy: 0.752628, best_score: 0.760896\n",
            "Epoch: 802, train_loss: 0.647384, val_loss: 0.963173, val_accuracy: 0.752628, best_score: 0.760896\n",
            "Epoch: 803, train_loss: 0.630463, val_loss: 0.955199, val_accuracy: 0.755255, best_score: 0.760896\n",
            "Epoch: 804, train_loss: 0.498379, val_loss: 0.927964, val_accuracy: 0.757032, best_score: 0.760896\n",
            "Epoch: 805, train_loss: 0.640031, val_loss: 0.877390, val_accuracy: 0.753787, best_score: 0.760896\n",
            "Epoch: 806, train_loss: 0.749751, val_loss: 0.863994, val_accuracy: 0.759042, best_score: 0.760896\n",
            "Epoch: 807, train_loss: 0.738262, val_loss: 0.943997, val_accuracy: 0.757573, best_score: 0.760896\n",
            "Epoch: 808, train_loss: 0.707468, val_loss: 0.922378, val_accuracy: 0.757032, best_score: 0.760896\n",
            "Epoch: 809, train_loss: 0.740469, val_loss: 0.938315, val_accuracy: 0.751236, best_score: 0.760896\n",
            "Epoch: 810, train_loss: 0.721723, val_loss: 0.914630, val_accuracy: 0.755023, best_score: 0.760896\n",
            "Epoch: 811, train_loss: 0.448172, val_loss: 1.080722, val_accuracy: 0.750000, best_score: 0.760896\n",
            "Epoch: 812, train_loss: 0.576367, val_loss: 1.014799, val_accuracy: 0.757651, best_score: 0.760896\n",
            "Epoch: 813, train_loss: 0.560164, val_loss: 1.013633, val_accuracy: 0.751005, best_score: 0.760896\n",
            "Epoch: 814, train_loss: 0.531323, val_loss: 0.978846, val_accuracy: 0.752705, best_score: 0.760896\n",
            "Epoch: 815, train_loss: 0.540016, val_loss: 0.970948, val_accuracy: 0.746368, best_score: 0.760896\n",
            "Epoch: 816, train_loss: 0.407653, val_loss: 0.874779, val_accuracy: 0.749614, best_score: 0.760896\n",
            "Epoch: 817, train_loss: 0.568852, val_loss: 0.950703, val_accuracy: 0.754946, best_score: 0.760896\n",
            "Epoch: 818, train_loss: 0.481081, val_loss: 0.980137, val_accuracy: 0.751546, best_score: 0.760896\n",
            "Epoch: 819, train_loss: 0.696041, val_loss: 0.925154, val_accuracy: 0.754328, best_score: 0.760896\n",
            "Epoch: 820, train_loss: 0.774788, val_loss: 0.937379, val_accuracy: 0.751082, best_score: 0.760896\n",
            "Epoch: 821, train_loss: 0.676885, val_loss: 0.895233, val_accuracy: 0.757187, best_score: 0.760896\n",
            "Epoch: 822, train_loss: 0.523946, val_loss: 0.926434, val_accuracy: 0.745131, best_score: 0.760896\n",
            "Epoch: 823, train_loss: 0.776606, val_loss: 0.909490, val_accuracy: 0.757264, best_score: 0.760896\n",
            "Epoch: 824, train_loss: 0.705327, val_loss: 0.928215, val_accuracy: 0.754096, best_score: 0.760896\n",
            "Epoch: 825, train_loss: 0.586845, val_loss: 0.962435, val_accuracy: 0.754946, best_score: 0.760896\n",
            "Epoch: 826, train_loss: 0.468406, val_loss: 0.927837, val_accuracy: 0.752473, best_score: 0.760896\n",
            "Epoch: 827, train_loss: 0.547746, val_loss: 0.901127, val_accuracy: 0.757419, best_score: 0.760896\n",
            "Epoch: 828, train_loss: 0.551751, val_loss: 0.939976, val_accuracy: 0.760587, best_score: 0.760896\n",
            "Epoch: 829, train_loss: 0.503766, val_loss: 0.968012, val_accuracy: 0.751236, best_score: 0.760896\n",
            "Epoch: 830, train_loss: 0.397260, val_loss: 0.878477, val_accuracy: 0.752628, best_score: 0.760896\n",
            "Epoch: 831, train_loss: 0.762680, val_loss: 0.959292, val_accuracy: 0.753864, best_score: 0.760896\n",
            "Epoch: 832, train_loss: 0.523516, val_loss: 0.996610, val_accuracy: 0.753168, best_score: 0.760896\n",
            "Epoch: 833, train_loss: 0.790587, val_loss: 1.012830, val_accuracy: 0.752396, best_score: 0.760896\n",
            "Epoch: 834, train_loss: 0.554112, val_loss: 1.019749, val_accuracy: 0.755023, best_score: 0.760896\n",
            "Epoch: 835, train_loss: 0.808510, val_loss: 0.968299, val_accuracy: 0.753709, best_score: 0.760896\n",
            "Epoch: 836, train_loss: 0.366477, val_loss: 0.874759, val_accuracy: 0.757651, best_score: 0.760896\n",
            "Epoch: 837, train_loss: 0.476357, val_loss: 0.984221, val_accuracy: 0.749382, best_score: 0.760896\n",
            "Epoch: 838, train_loss: 0.577097, val_loss: 1.002176, val_accuracy: 0.755023, best_score: 0.760896\n",
            "Epoch: 839, train_loss: 0.655492, val_loss: 0.911054, val_accuracy: 0.757883, best_score: 0.760896\n",
            "Epoch: 840, train_loss: 0.701935, val_loss: 1.075722, val_accuracy: 0.749536, best_score: 0.760896\n",
            "Epoch: 841, train_loss: 0.708950, val_loss: 0.952537, val_accuracy: 0.756491, best_score: 0.760896\n",
            "Epoch: 842, train_loss: 0.567474, val_loss: 0.939862, val_accuracy: 0.756646, best_score: 0.760896\n",
            "Epoch: 843, train_loss: 0.625599, val_loss: 0.936069, val_accuracy: 0.759042, best_score: 0.760896\n",
            "Epoch: 844, train_loss: 0.554485, val_loss: 0.937618, val_accuracy: 0.758733, best_score: 0.760896\n",
            "Epoch: 845, train_loss: 0.535628, val_loss: 0.982160, val_accuracy: 0.754714, best_score: 0.760896\n",
            "Epoch: 846, train_loss: 0.488249, val_loss: 0.988721, val_accuracy: 0.752628, best_score: 0.760896\n",
            "Epoch: 847, train_loss: 0.454436, val_loss: 0.982248, val_accuracy: 0.754019, best_score: 0.760896\n",
            "Epoch: 848, train_loss: 0.594780, val_loss: 0.919491, val_accuracy: 0.756028, best_score: 0.760896\n",
            "Epoch: 849, train_loss: 0.479577, val_loss: 0.924229, val_accuracy: 0.753246, best_score: 0.760896\n",
            "Epoch: 850, train_loss: 0.647049, val_loss: 0.923368, val_accuracy: 0.760974, best_score: 0.760974\n",
            "Epoch: 851, train_loss: 0.660688, val_loss: 0.857267, val_accuracy: 0.757264, best_score: 0.760974\n",
            "Epoch: 852, train_loss: 0.485780, val_loss: 0.963259, val_accuracy: 0.756723, best_score: 0.760974\n",
            "Epoch: 853, train_loss: 0.683029, val_loss: 0.957220, val_accuracy: 0.756491, best_score: 0.760974\n",
            "Epoch: 854, train_loss: 0.514034, val_loss: 0.981911, val_accuracy: 0.751159, best_score: 0.760974\n",
            "Epoch: 855, train_loss: 0.857813, val_loss: 0.974500, val_accuracy: 0.753168, best_score: 0.760974\n",
            "Epoch: 856, train_loss: 0.685052, val_loss: 1.018006, val_accuracy: 0.756801, best_score: 0.760974\n",
            "Epoch: 857, train_loss: 0.612673, val_loss: 0.961575, val_accuracy: 0.756182, best_score: 0.760974\n",
            "Epoch: 858, train_loss: 0.596976, val_loss: 0.892797, val_accuracy: 0.754250, best_score: 0.760974\n",
            "Epoch: 859, train_loss: 0.649200, val_loss: 0.904161, val_accuracy: 0.754096, best_score: 0.760974\n",
            "Epoch: 860, train_loss: 0.720266, val_loss: 0.888895, val_accuracy: 0.755410, best_score: 0.760974\n",
            "Epoch: 861, train_loss: 0.615538, val_loss: 0.975067, val_accuracy: 0.751236, best_score: 0.760974\n",
            "Epoch: 862, train_loss: 0.667953, val_loss: 0.942961, val_accuracy: 0.751700, best_score: 0.760974\n",
            "Epoch: 863, train_loss: 0.779985, val_loss: 0.899549, val_accuracy: 0.755873, best_score: 0.760974\n",
            "Epoch: 864, train_loss: 0.604917, val_loss: 0.984296, val_accuracy: 0.754096, best_score: 0.760974\n",
            "Epoch: 865, train_loss: 0.397252, val_loss: 0.875621, val_accuracy: 0.759892, best_score: 0.760974\n",
            "Epoch: 866, train_loss: 0.521679, val_loss: 0.863901, val_accuracy: 0.752705, best_score: 0.760974\n",
            "Epoch: 867, train_loss: 0.676298, val_loss: 0.966945, val_accuracy: 0.753864, best_score: 0.760974\n",
            "Epoch: 868, train_loss: 0.572340, val_loss: 0.980521, val_accuracy: 0.757264, best_score: 0.760974\n",
            "Epoch: 869, train_loss: 0.552012, val_loss: 0.899564, val_accuracy: 0.756337, best_score: 0.760974\n",
            "Epoch: 870, train_loss: 0.496051, val_loss: 1.014834, val_accuracy: 0.748609, best_score: 0.760974\n",
            "Epoch: 871, train_loss: 0.603637, val_loss: 0.900054, val_accuracy: 0.759428, best_score: 0.760974\n",
            "Epoch: 872, train_loss: 0.770713, val_loss: 0.988215, val_accuracy: 0.749768, best_score: 0.760974\n",
            "Epoch: 873, train_loss: 0.636083, val_loss: 0.874774, val_accuracy: 0.757419, best_score: 0.760974\n",
            "Epoch: 874, train_loss: 0.564573, val_loss: 0.858046, val_accuracy: 0.753864, best_score: 0.760974\n",
            "Epoch: 875, train_loss: 0.481583, val_loss: 0.950656, val_accuracy: 0.753014, best_score: 0.760974\n",
            "Epoch: 876, train_loss: 0.509574, val_loss: 0.963592, val_accuracy: 0.755951, best_score: 0.760974\n",
            "Epoch: 877, train_loss: 0.672706, val_loss: 0.874961, val_accuracy: 0.755873, best_score: 0.760974\n",
            "Epoch: 878, train_loss: 0.611322, val_loss: 0.893950, val_accuracy: 0.760046, best_score: 0.760974\n",
            "Epoch: 879, train_loss: 0.571433, val_loss: 0.867566, val_accuracy: 0.760510, best_score: 0.760974\n",
            "Epoch: 880, train_loss: 0.668388, val_loss: 1.002789, val_accuracy: 0.752164, best_score: 0.760974\n",
            "Epoch: 881, train_loss: 0.669840, val_loss: 0.964778, val_accuracy: 0.757805, best_score: 0.760974\n",
            "Epoch: 882, train_loss: 0.540191, val_loss: 0.986850, val_accuracy: 0.754637, best_score: 0.760974\n",
            "Epoch: 883, train_loss: 0.746829, val_loss: 0.909378, val_accuracy: 0.752550, best_score: 0.760974\n",
            "Epoch: 884, train_loss: 0.562728, val_loss: 0.941570, val_accuracy: 0.750773, best_score: 0.760974\n",
            "Epoch: 885, train_loss: 0.751089, val_loss: 0.932236, val_accuracy: 0.761360, best_score: 0.761360\n",
            "Epoch: 886, train_loss: 0.408259, val_loss: 0.993184, val_accuracy: 0.755487, best_score: 0.761360\n",
            "Epoch: 887, train_loss: 0.529864, val_loss: 0.989667, val_accuracy: 0.752473, best_score: 0.761360\n",
            "Epoch: 888, train_loss: 0.459926, val_loss: 0.913512, val_accuracy: 0.757496, best_score: 0.761360\n",
            "Epoch: 889, train_loss: 0.552009, val_loss: 0.949626, val_accuracy: 0.746136, best_score: 0.761360\n",
            "Epoch: 890, train_loss: 0.506263, val_loss: 0.892825, val_accuracy: 0.758501, best_score: 0.761360\n",
            "Epoch: 891, train_loss: 0.643703, val_loss: 0.894523, val_accuracy: 0.758192, best_score: 0.761360\n",
            "Epoch: 892, train_loss: 0.843616, val_loss: 0.941682, val_accuracy: 0.758655, best_score: 0.761360\n",
            "Epoch: 893, train_loss: 0.781627, val_loss: 0.939595, val_accuracy: 0.755255, best_score: 0.761360\n",
            "Epoch: 894, train_loss: 0.456487, val_loss: 0.979227, val_accuracy: 0.755410, best_score: 0.761360\n",
            "Epoch: 895, train_loss: 0.794185, val_loss: 0.955751, val_accuracy: 0.757032, best_score: 0.761360\n",
            "Epoch: 896, train_loss: 0.593138, val_loss: 0.944113, val_accuracy: 0.756723, best_score: 0.761360\n",
            "Epoch: 897, train_loss: 0.480252, val_loss: 0.980637, val_accuracy: 0.750155, best_score: 0.761360\n",
            "Epoch: 898, train_loss: 0.639449, val_loss: 0.904458, val_accuracy: 0.754482, best_score: 0.761360\n",
            "Epoch: 899, train_loss: 0.586938, val_loss: 0.954270, val_accuracy: 0.754328, best_score: 0.761360\n",
            "Epoch: 900, train_loss: 0.797734, val_loss: 0.859495, val_accuracy: 0.756414, best_score: 0.761360\n",
            "Epoch: 901, train_loss: 0.518180, val_loss: 0.912368, val_accuracy: 0.756569, best_score: 0.761360\n",
            "Epoch: 902, train_loss: 0.559333, val_loss: 0.886453, val_accuracy: 0.757805, best_score: 0.761360\n",
            "Epoch: 903, train_loss: 0.585164, val_loss: 0.868497, val_accuracy: 0.756801, best_score: 0.761360\n",
            "Epoch: 904, train_loss: 0.530227, val_loss: 0.915090, val_accuracy: 0.755100, best_score: 0.761360\n",
            "Epoch: 905, train_loss: 0.747477, val_loss: 0.926861, val_accuracy: 0.757110, best_score: 0.761360\n",
            "Epoch: 906, train_loss: 0.538970, val_loss: 0.894768, val_accuracy: 0.753323, best_score: 0.761360\n",
            "Epoch: 907, train_loss: 0.563881, val_loss: 0.935589, val_accuracy: 0.753864, best_score: 0.761360\n",
            "Epoch: 908, train_loss: 0.738199, val_loss: 0.913912, val_accuracy: 0.755100, best_score: 0.761360\n",
            "Epoch: 909, train_loss: 0.493842, val_loss: 0.961040, val_accuracy: 0.753555, best_score: 0.761360\n",
            "Epoch: 910, train_loss: 0.532837, val_loss: 1.020797, val_accuracy: 0.750927, best_score: 0.761360\n",
            "Epoch: 911, train_loss: 0.700822, val_loss: 0.887102, val_accuracy: 0.760355, best_score: 0.761360\n",
            "Epoch: 912, train_loss: 0.515662, val_loss: 0.957788, val_accuracy: 0.750386, best_score: 0.761360\n",
            "Epoch: 913, train_loss: 0.693247, val_loss: 0.839248, val_accuracy: 0.756955, best_score: 0.761360\n",
            "Epoch: 914, train_loss: 0.437892, val_loss: 0.893866, val_accuracy: 0.758964, best_score: 0.761360\n",
            "Epoch: 915, train_loss: 0.608994, val_loss: 0.893253, val_accuracy: 0.751546, best_score: 0.761360\n",
            "Epoch: 916, train_loss: 0.751647, val_loss: 0.924874, val_accuracy: 0.754328, best_score: 0.761360\n",
            "Epoch: 917, train_loss: 0.660173, val_loss: 0.833189, val_accuracy: 0.755641, best_score: 0.761360\n",
            "Epoch: 918, train_loss: 0.549622, val_loss: 0.893839, val_accuracy: 0.751005, best_score: 0.761360\n",
            "Epoch: 919, train_loss: 0.564001, val_loss: 0.895281, val_accuracy: 0.754946, best_score: 0.761360\n",
            "Epoch: 920, train_loss: 0.756205, val_loss: 0.933058, val_accuracy: 0.756028, best_score: 0.761360\n",
            "Epoch: 921, train_loss: 0.587541, val_loss: 0.946806, val_accuracy: 0.747836, best_score: 0.761360\n",
            "Epoch: 922, train_loss: 0.583981, val_loss: 0.880163, val_accuracy: 0.757110, best_score: 0.761360\n",
            "Epoch: 923, train_loss: 0.499916, val_loss: 0.857898, val_accuracy: 0.757419, best_score: 0.761360\n",
            "Epoch: 924, train_loss: 0.523901, val_loss: 0.862990, val_accuracy: 0.757419, best_score: 0.761360\n",
            "Epoch: 925, train_loss: 0.554065, val_loss: 0.919437, val_accuracy: 0.755410, best_score: 0.761360\n",
            "Epoch: 926, train_loss: 0.589481, val_loss: 0.892323, val_accuracy: 0.757032, best_score: 0.761360\n",
            "Epoch: 927, train_loss: 0.667916, val_loss: 0.855306, val_accuracy: 0.755255, best_score: 0.761360\n",
            "Epoch: 928, train_loss: 0.552167, val_loss: 0.894252, val_accuracy: 0.759119, best_score: 0.761360\n",
            "Epoch: 929, train_loss: 0.802095, val_loss: 0.922495, val_accuracy: 0.751855, best_score: 0.761360\n",
            "Epoch: 930, train_loss: 0.680881, val_loss: 0.859547, val_accuracy: 0.757032, best_score: 0.761360\n",
            "Epoch: 931, train_loss: 0.563199, val_loss: 0.951304, val_accuracy: 0.747218, best_score: 0.761360\n",
            "Epoch: 932, train_loss: 0.811652, val_loss: 0.902009, val_accuracy: 0.757496, best_score: 0.761360\n",
            "Epoch: 933, train_loss: 0.598305, val_loss: 0.904369, val_accuracy: 0.757573, best_score: 0.761360\n",
            "Epoch: 934, train_loss: 0.590635, val_loss: 0.882400, val_accuracy: 0.756723, best_score: 0.761360\n",
            "Epoch: 935, train_loss: 0.546814, val_loss: 0.850456, val_accuracy: 0.757419, best_score: 0.761360\n",
            "Epoch: 936, train_loss: 0.483768, val_loss: 0.951663, val_accuracy: 0.754560, best_score: 0.761360\n",
            "Epoch: 937, train_loss: 0.557323, val_loss: 0.908841, val_accuracy: 0.753246, best_score: 0.761360\n",
            "Epoch: 938, train_loss: 0.499985, val_loss: 0.909299, val_accuracy: 0.752009, best_score: 0.761360\n",
            "Epoch: 939, train_loss: 0.617339, val_loss: 0.903680, val_accuracy: 0.752705, best_score: 0.761360\n",
            "Epoch: 940, train_loss: 0.633173, val_loss: 0.830925, val_accuracy: 0.757728, best_score: 0.761360\n",
            "Epoch: 941, train_loss: 0.510771, val_loss: 0.911696, val_accuracy: 0.749614, best_score: 0.761360\n",
            "Epoch: 942, train_loss: 0.675172, val_loss: 0.899565, val_accuracy: 0.756955, best_score: 0.761360\n",
            "Epoch: 943, train_loss: 0.590476, val_loss: 0.893280, val_accuracy: 0.757264, best_score: 0.761360\n",
            "Epoch: 944, train_loss: 0.486076, val_loss: 0.885179, val_accuracy: 0.756569, best_score: 0.761360\n",
            "Epoch: 945, train_loss: 0.537448, val_loss: 0.868476, val_accuracy: 0.755951, best_score: 0.761360\n",
            "Epoch: 946, train_loss: 0.579849, val_loss: 0.839184, val_accuracy: 0.752628, best_score: 0.761360\n",
            "Epoch: 947, train_loss: 0.582942, val_loss: 0.947688, val_accuracy: 0.757342, best_score: 0.761360\n",
            "Epoch: 948, train_loss: 0.705708, val_loss: 0.883147, val_accuracy: 0.756878, best_score: 0.761360\n",
            "Epoch: 949, train_loss: 0.607657, val_loss: 0.957351, val_accuracy: 0.756414, best_score: 0.761360\n",
            "Epoch: 950, train_loss: 0.686410, val_loss: 0.893408, val_accuracy: 0.754946, best_score: 0.761360\n",
            "Epoch: 951, train_loss: 0.413276, val_loss: 0.916619, val_accuracy: 0.753632, best_score: 0.761360\n",
            "Epoch: 952, train_loss: 0.481359, val_loss: 0.862218, val_accuracy: 0.753555, best_score: 0.761360\n",
            "Epoch: 953, train_loss: 0.496903, val_loss: 0.906167, val_accuracy: 0.751855, best_score: 0.761360\n",
            "Epoch: 954, train_loss: 0.684027, val_loss: 0.900335, val_accuracy: 0.754869, best_score: 0.761360\n",
            "Epoch: 955, train_loss: 0.401972, val_loss: 0.892417, val_accuracy: 0.756260, best_score: 0.761360\n",
            "Epoch: 956, train_loss: 0.588290, val_loss: 0.922359, val_accuracy: 0.753014, best_score: 0.761360\n",
            "Epoch: 957, train_loss: 0.802544, val_loss: 0.886526, val_accuracy: 0.757805, best_score: 0.761360\n",
            "Epoch: 958, train_loss: 0.656150, val_loss: 0.940463, val_accuracy: 0.754791, best_score: 0.761360\n",
            "Epoch: 959, train_loss: 0.561573, val_loss: 0.949877, val_accuracy: 0.756491, best_score: 0.761360\n",
            "Epoch: 960, train_loss: 0.562605, val_loss: 0.899814, val_accuracy: 0.757110, best_score: 0.761360\n",
            "Epoch: 961, train_loss: 0.386785, val_loss: 0.974773, val_accuracy: 0.758423, best_score: 0.761360\n",
            "Epoch: 962, train_loss: 0.752977, val_loss: 0.902557, val_accuracy: 0.753400, best_score: 0.761360\n",
            "Epoch: 963, train_loss: 0.667087, val_loss: 0.883253, val_accuracy: 0.755641, best_score: 0.761360\n",
            "Epoch: 964, train_loss: 0.530369, val_loss: 0.943850, val_accuracy: 0.753478, best_score: 0.761360\n",
            "Epoch: 965, train_loss: 0.565250, val_loss: 0.912574, val_accuracy: 0.753014, best_score: 0.761360\n",
            "Epoch: 966, train_loss: 0.550009, val_loss: 0.911226, val_accuracy: 0.753787, best_score: 0.761360\n",
            "Epoch: 967, train_loss: 0.604511, val_loss: 0.886934, val_accuracy: 0.757573, best_score: 0.761360\n",
            "Epoch: 968, train_loss: 0.420552, val_loss: 0.944400, val_accuracy: 0.752859, best_score: 0.761360\n",
            "Epoch: 969, train_loss: 0.592509, val_loss: 0.983969, val_accuracy: 0.757342, best_score: 0.761360\n",
            "Epoch: 970, train_loss: 0.605045, val_loss: 0.980967, val_accuracy: 0.754946, best_score: 0.761360\n",
            "Epoch: 971, train_loss: 0.835731, val_loss: 0.958384, val_accuracy: 0.752628, best_score: 0.761360\n",
            "Epoch: 972, train_loss: 0.673666, val_loss: 0.978335, val_accuracy: 0.757728, best_score: 0.761360\n",
            "Epoch: 973, train_loss: 0.785312, val_loss: 0.877328, val_accuracy: 0.756414, best_score: 0.761360\n",
            "Epoch: 974, train_loss: 0.517377, val_loss: 0.965798, val_accuracy: 0.753941, best_score: 0.761360\n",
            "Epoch: 975, train_loss: 0.859179, val_loss: 0.928063, val_accuracy: 0.756105, best_score: 0.761360\n",
            "Epoch: 976, train_loss: 0.526881, val_loss: 0.951975, val_accuracy: 0.750618, best_score: 0.761360\n",
            "Epoch: 977, train_loss: 0.529179, val_loss: 0.988848, val_accuracy: 0.750773, best_score: 0.761360\n",
            "Epoch: 978, train_loss: 0.655819, val_loss: 0.946887, val_accuracy: 0.755873, best_score: 0.761360\n",
            "Epoch: 979, train_loss: 0.617854, val_loss: 0.905036, val_accuracy: 0.753323, best_score: 0.761360\n",
            "Epoch: 980, train_loss: 0.492747, val_loss: 0.913780, val_accuracy: 0.748609, best_score: 0.761360\n",
            "Epoch: 981, train_loss: 0.504082, val_loss: 0.912077, val_accuracy: 0.754405, best_score: 0.761360\n",
            "Epoch: 982, train_loss: 0.539430, val_loss: 0.896211, val_accuracy: 0.758192, best_score: 0.761360\n",
            "Epoch: 983, train_loss: 0.796124, val_loss: 0.921764, val_accuracy: 0.756260, best_score: 0.761360\n",
            "Epoch: 984, train_loss: 0.658517, val_loss: 0.875141, val_accuracy: 0.755796, best_score: 0.761360\n",
            "Epoch: 985, train_loss: 0.474639, val_loss: 0.904231, val_accuracy: 0.757187, best_score: 0.761360\n",
            "Epoch: 986, train_loss: 0.565322, val_loss: 0.938661, val_accuracy: 0.752473, best_score: 0.761360\n",
            "Epoch: 987, train_loss: 0.562006, val_loss: 0.911115, val_accuracy: 0.757805, best_score: 0.761360\n",
            "Epoch: 988, train_loss: 0.482676, val_loss: 0.948099, val_accuracy: 0.756260, best_score: 0.761360\n",
            "Epoch: 989, train_loss: 0.606525, val_loss: 0.950660, val_accuracy: 0.760124, best_score: 0.761360\n",
            "Epoch: 990, train_loss: 0.653521, val_loss: 0.959003, val_accuracy: 0.756182, best_score: 0.761360\n",
            "Epoch: 991, train_loss: 0.440005, val_loss: 0.884019, val_accuracy: 0.756801, best_score: 0.761360\n",
            "Epoch: 992, train_loss: 0.577182, val_loss: 0.911380, val_accuracy: 0.754946, best_score: 0.761360\n",
            "Epoch: 993, train_loss: 0.495626, val_loss: 0.850582, val_accuracy: 0.753632, best_score: 0.761360\n",
            "Epoch: 994, train_loss: 0.519669, val_loss: 1.005706, val_accuracy: 0.754791, best_score: 0.761360\n",
            "Epoch: 995, train_loss: 0.632722, val_loss: 0.943844, val_accuracy: 0.756337, best_score: 0.761360\n",
            "Epoch: 996, train_loss: 0.671304, val_loss: 0.931482, val_accuracy: 0.753014, best_score: 0.761360\n",
            "Epoch: 997, train_loss: 0.538222, val_loss: 0.915994, val_accuracy: 0.754405, best_score: 0.761360\n",
            "Epoch: 998, train_loss: 0.556408, val_loss: 0.996382, val_accuracy: 0.752241, best_score: 0.761360\n",
            "Epoch: 999, train_loss: 0.672399, val_loss: 0.928435, val_accuracy: 0.757573, best_score: 0.761360\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 1e-2\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "n_epochs = 1000\n",
        "best_score = 0\n",
        "#model.load_state_dict(torch.load('best-model-paramteres.pt'))\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    model.train(True)\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        #print(labels)\n",
        "        \n",
        "        outputs = model(imgs)   # important:  nn.Conv2d expects a B × C × H × W shaped tensor as input\n",
        "        train_loss = loss_fn(outputs, labels)\n",
        "  \n",
        "        optimizer.zero_grad()\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            \n",
        "            outputs = model(imgs)\n",
        "            val_loss = loss_fn(outputs, labels)\n",
        "            \n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "            #print(predicted)\n",
        "            total += labels.shape[0]\n",
        "            correct += int((predicted == labels).sum())\n",
        "    val_accuracy = correct / total\n",
        "    if val_accuracy > best_score:\n",
        "        torch.save(model.state_dict(), 'best-model2-paramteres.pt')\n",
        "        best_score = val_accuracy\n",
        "    print(\"Epoch: %d, train_loss: %f, val_loss: %f, val_accuracy: %f, best_score: %f\" % (epoch, float(train_loss), float(val_loss), val_accuracy, best_score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for Sequential:\n\tsize mismatch for 4.weight: copying a param with shape torch.Size([32, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 64, 5, 5]).\n\tsize mismatch for 16.weight: copying a param with shape torch.Size([3, 968]) from checkpoint, the shape in current model is torch.Size([3, 800]).",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m/home/oreomilkshake/HW/MachineLearning/FacialExpressionClassification/mariano_alex_assignment3.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/oreomilkshake/HW/MachineLearning/FacialExpressionClassification/mariano_alex_assignment3.ipynb#X45sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mload_state_dict(torch\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mbest-model-paramteres.pt\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/oreomilkshake/HW/MachineLearning/FacialExpressionClassification/mariano_alex_assignment3.ipynb#X45sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/oreomilkshake/HW/MachineLearning/FacialExpressionClassification/mariano_alex_assignment3.ipynb#X45sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     model\u001b[39m.\u001b[39mtrain(\u001b[39mFalse\u001b[39;00m)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Sequential:\n\tsize mismatch for 4.weight: copying a param with shape torch.Size([32, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 64, 5, 5]).\n\tsize mismatch for 16.weight: copying a param with shape torch.Size([3, 968]) from checkpoint, the shape in current model is torch.Size([3, 800])."
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('best-model-paramteres.pt'))\n",
        "with torch.no_grad():\n",
        "    model.train(False)\n",
        "    for imgs, labels in val_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        \n",
        "        outputs = model(imgs)\n",
        "        val_loss = loss_fn(outputs, labels)\n",
        "        \n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "    val_accuracy = correct / total\n",
        "    print(\"Epoch: %d, train_loss: %f, val_loss: %f, val_accuracy: %f, best_score: %f\" % (epoch, float(train_loss), float(val_loss), val_accuracy, best_score))\n",
        "    \n",
        "torch.cuda.empty_cache()\n",
        "test_data = pd.read_csv('test_data.csv')\n",
        "processed_test_data = test_data.to_numpy()\n",
        "processed_test_dataset = CustomDataset(processed_test_data, train_target,\n",
        "    transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.4915, 0.2470)\n",
        "    ]))\n",
        "processed_test_data_loader = torch.utils.data.DataLoader(processed_test_dataset, batch_size=1, shuffle=False,  **kwargs)\n",
        "output_list = np.zeros(processed_test_dataset.__len__())\n",
        "iter = 0\n",
        "for test_img, labels in processed_test_data_loader:\n",
        "    test_img = test_img.to(device)\n",
        "    output = model(test_img)\n",
        "    _, predicted = torch.max(outputs, dim=1)\n",
        "    print(predicted)\n",
        "    output_list[iter] = predicted\n",
        "    iter += 1\n",
        "output_dataframe = pd.DataFrame(output_list)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
