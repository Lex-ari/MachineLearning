{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0A_JriDGhBkF"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT7ME9FqVIg_",
        "outputId": "736e8ec6-e47c-4003-f8af-c2aa8f366029"
      },
      "outputs": [],
      "source": [
        "# Module imports\n",
        "from __future__ import print_function\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils import shuffle\n",
        "%matplotlib inline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset\n",
        "import cv2\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "ZQ50JDWGVpWt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 16174 entries, 0 to 16173\n",
            "Columns: 2304 entries, 146 to 81.32\n",
            "dtypes: int64(2304)\n",
            "memory usage: 284.3 MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 16174 entries, 0 to 16173\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype\n",
            "---  ------  --------------  -----\n",
            " 0   1       16174 non-null  int64\n",
            "dtypes: int64(1)\n",
            "memory usage: 126.5 KB\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>16174.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.059973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.741898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  1\n",
              "count  16174.000000\n",
              "mean       1.059973\n",
              "std        0.741898\n",
              "min        0.000000\n",
              "25%        1.000000\n",
              "50%        1.000000\n",
              "75%        2.000000\n",
              "max        2.000000"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rawdata = pd.read_csv('train_data.csv')\n",
        "# display the top rows\n",
        "rawdata.head(10)\n",
        "# get a quick description of the data, including # of rows, # of features, name of each feature, type of each feature, # of non-null values\n",
        "rawdata.info()\n",
        "# show a summary of the numerical attributes\n",
        "rawdata.describe()\n",
        "\n",
        "rawtargetdata = pd.read_csv('train_target.csv')\n",
        "# display the top rows\n",
        "rawtargetdata.head(10)\n",
        "# get a quick description of the data, including # of rows, # of features, name of each feature, type of each feature, # of non-null values\n",
        "rawtargetdata.info()\n",
        "# show a summary of the numerical attributes\n",
        "rawtargetdata.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vG3znnVYh3Fo"
      },
      "source": [
        "#  Task 1: Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "Ylr3j8GD_Eoq"
      },
      "outputs": [],
      "source": [
        "# num_pipeline = Pipeline([\n",
        "#     ('std_scaler', StandardScaler()),\n",
        "# ])\n",
        "\n",
        "# data_preprocessed = num_pipeline.fit_transform(rawdata)\n",
        "data_preprocessed = rawdata.to_numpy()\n",
        "targets_preprocessed = rawtargetdata.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qey-gjetiXTI"
      },
      "source": [
        "# Task 2: Split Dataset for Training, Validation, and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_data.shape: (12939, 2304)\n",
            "train_target.shape: (12939, 1)\n",
            "\n",
            "valid_data.shape: (3235, 2304)\n",
            "valid_target.shape: (3235, 1)\n"
          ]
        }
      ],
      "source": [
        "train_data, valid_data, train_target, valid_target = train_test_split(data_preprocessed, targets_preprocessed, test_size = 0.20, random_state = 42)\n",
        "\n",
        "#print(train_data)\n",
        "print(f\"train_data.shape: {train_data.shape}\")\n",
        "print(f\"train_target.shape: {train_target.shape}\")\n",
        "print()\n",
        "print(f\"valid_data.shape: {valid_data.shape}\")\n",
        "print(f\"valid_target.shape: {valid_target.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, train_data, train_target, transform = None, target_transform = None):\n",
        "        super().__init__()\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.data = []\n",
        "        self.targets = []\n",
        "        \n",
        "        for image in train_data:\n",
        "            reshaped_array = np.reshape(image, (48, 48))\n",
        "            pil_image = Image.fromarray(np.uint8(reshaped_array))\n",
        "            self.data.append(pil_image)\n",
        "        if train_target is not None:\n",
        "            for target in train_target:\n",
        "                self.targets.append(target[0])\n",
        "        #self.data = np.vstack(self.data).reshape(-1, 48, 48)\n",
        "        #self.data = self.data.transpose((0, 1, 2))  # convert to Hight by Width by Channel\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        img, target = self.data[idx], self.targets[idx]\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "        return img, target\n",
        "\n",
        "    def getitem_notarget(self, idx):\n",
        "        img = self.data[idx]\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainingDataset = CustomDataset(train_data, train_target,\n",
        "    transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.4915, 0.2470)\n",
        "    ]))\n",
        "validationDataset = CustomDataset(valid_data, valid_target,\n",
        "    transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.4915, 0.2470)\n",
        "    ]))\n",
        "\n",
        "# print(trainingDataset.data[0])\n",
        "\n",
        "# image, target = trainingDataset.__getitem__(0)\n",
        "# plt.imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "kwargs = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available()else {}\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(trainingDataset, batch_size=64, shuffle=True,  **kwargs)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(validationDataset, batch_size=64,shuffle=False, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_out = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
              "  (1): ReLU()\n",
              "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (3): Dropout2d(p=0.4, inplace=False)\n",
              "  (4): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
              "  (5): ReLU()\n",
              "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (7): Dropout2d(p=0.4, inplace=False)\n",
              "  (8): ReLU()\n",
              "  (9): Dropout2d(p=0.4, inplace=False)\n",
              "  (10): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (11): ReLU()\n",
              "  (12): Dropout2d(p=0.4, inplace=False)\n",
              "  (13): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (14): ReLU()\n",
              "  (15): Flatten(start_dim=1, end_dim=-1)\n",
              "  (16): Linear(in_features=800, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequential_model = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=5, padding=1),\n",
        "            nn.ReLU(),\n",
        "            #nn.Tanh(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout2d(p=0.4),\n",
        "            nn.Conv2d(64, 32, kernel_size=5, padding=1),\n",
        "            nn.ReLU(),\n",
        "            #nn.Tanh(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout2d(p=0.4),\n",
        "            nn.ReLU(),\n",
        "            #nn.Tanh(),\n",
        "            nn.Dropout2d(p=0.4),\n",
        "            nn.Conv2d(32, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(p=0.4),\n",
        "            nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(), \n",
        "            nn.Linear(800, n_out)\n",
        ")\n",
        "\n",
        "model = sequential_model\n",
        "\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0, train_loss: 0.323546, val_loss: 0.469360, val_accuracy: 0.775270, best_score: 0.775270\n",
            "Epoch: 1, train_loss: 0.421129, val_loss: 0.445907, val_accuracy: 0.773416, best_score: 0.775270\n",
            "Epoch: 2, train_loss: 0.430372, val_loss: 0.452514, val_accuracy: 0.771561, best_score: 0.775270\n",
            "Epoch: 3, train_loss: 0.547438, val_loss: 0.431572, val_accuracy: 0.780526, best_score: 0.780526\n",
            "Epoch: 4, train_loss: 0.369719, val_loss: 0.442071, val_accuracy: 0.768161, best_score: 0.780526\n",
            "Epoch: 5, train_loss: 0.362379, val_loss: 0.435241, val_accuracy: 0.777434, best_score: 0.780526\n",
            "Epoch: 6, train_loss: 0.428170, val_loss: 0.467889, val_accuracy: 0.767852, best_score: 0.780526\n",
            "Epoch: 7, train_loss: 0.708088, val_loss: 0.461422, val_accuracy: 0.771252, best_score: 0.780526\n",
            "Epoch: 8, train_loss: 0.928345, val_loss: 0.427315, val_accuracy: 0.774343, best_score: 0.780526\n",
            "Epoch: 9, train_loss: 0.306673, val_loss: 0.465879, val_accuracy: 0.774961, best_score: 0.780526\n",
            "Epoch: 10, train_loss: 0.475009, val_loss: 0.433817, val_accuracy: 0.781762, best_score: 0.781762\n",
            "Epoch: 11, train_loss: 0.614586, val_loss: 0.433140, val_accuracy: 0.775580, best_score: 0.781762\n",
            "Epoch: 12, train_loss: 0.358634, val_loss: 0.434961, val_accuracy: 0.769397, best_score: 0.781762\n",
            "Epoch: 13, train_loss: 0.162673, val_loss: 0.434779, val_accuracy: 0.775270, best_score: 0.781762\n",
            "Epoch: 14, train_loss: 0.301711, val_loss: 0.436198, val_accuracy: 0.778053, best_score: 0.781762\n",
            "Epoch: 15, train_loss: 0.333912, val_loss: 0.429419, val_accuracy: 0.776816, best_score: 0.781762\n",
            "Epoch: 16, train_loss: 0.364258, val_loss: 0.451344, val_accuracy: 0.772798, best_score: 0.781762\n",
            "Epoch: 17, train_loss: 0.313082, val_loss: 0.421107, val_accuracy: 0.773416, best_score: 0.781762\n",
            "Epoch: 18, train_loss: 0.407675, val_loss: 0.422363, val_accuracy: 0.776507, best_score: 0.781762\n",
            "Epoch: 19, train_loss: 1.193716, val_loss: 0.502343, val_accuracy: 0.766924, best_score: 0.781762\n",
            "Epoch: 20, train_loss: 0.152288, val_loss: 0.444864, val_accuracy: 0.774343, best_score: 0.781762\n",
            "Epoch: 21, train_loss: 0.554601, val_loss: 0.441758, val_accuracy: 0.776507, best_score: 0.781762\n",
            "Epoch: 22, train_loss: 0.510163, val_loss: 0.434747, val_accuracy: 0.778053, best_score: 0.781762\n",
            "Epoch: 23, train_loss: 0.214512, val_loss: 0.411517, val_accuracy: 0.775889, best_score: 0.781762\n",
            "Epoch: 24, train_loss: 0.142402, val_loss: 0.470393, val_accuracy: 0.770325, best_score: 0.781762\n",
            "Epoch: 25, train_loss: 0.615256, val_loss: 0.443064, val_accuracy: 0.775580, best_score: 0.781762\n",
            "Epoch: 26, train_loss: 0.283277, val_loss: 0.433674, val_accuracy: 0.771870, best_score: 0.781762\n",
            "Epoch: 27, train_loss: 0.315421, val_loss: 0.422887, val_accuracy: 0.775270, best_score: 0.781762\n",
            "Epoch: 28, train_loss: 0.425658, val_loss: 0.415023, val_accuracy: 0.772179, best_score: 0.781762\n",
            "Epoch: 29, train_loss: 0.899138, val_loss: 0.409013, val_accuracy: 0.776198, best_score: 0.781762\n",
            "Epoch: 30, train_loss: 0.332165, val_loss: 0.418677, val_accuracy: 0.772179, best_score: 0.781762\n",
            "Epoch: 31, train_loss: 0.444017, val_loss: 0.443096, val_accuracy: 0.772488, best_score: 0.781762\n",
            "Epoch: 32, train_loss: 0.248738, val_loss: 0.434466, val_accuracy: 0.778053, best_score: 0.781762\n",
            "Epoch: 33, train_loss: 0.242370, val_loss: 0.412473, val_accuracy: 0.781144, best_score: 0.781762\n",
            "Epoch: 34, train_loss: 0.582933, val_loss: 0.423651, val_accuracy: 0.776816, best_score: 0.781762\n",
            "Epoch: 35, train_loss: 0.527746, val_loss: 0.409687, val_accuracy: 0.775889, best_score: 0.781762\n",
            "Epoch: 36, train_loss: 0.796644, val_loss: 0.420556, val_accuracy: 0.782071, best_score: 0.782071\n",
            "Epoch: 37, train_loss: 0.679996, val_loss: 0.434038, val_accuracy: 0.780835, best_score: 0.782071\n",
            "Epoch: 38, train_loss: 0.518752, val_loss: 0.425218, val_accuracy: 0.778980, best_score: 0.782071\n",
            "Epoch: 39, train_loss: 0.170207, val_loss: 0.446432, val_accuracy: 0.773416, best_score: 0.782071\n",
            "Epoch: 40, train_loss: 1.190892, val_loss: 0.414887, val_accuracy: 0.780835, best_score: 0.782071\n",
            "Epoch: 41, train_loss: 0.688079, val_loss: 0.421767, val_accuracy: 0.772488, best_score: 0.782071\n",
            "Epoch: 42, train_loss: 0.657333, val_loss: 0.418351, val_accuracy: 0.776507, best_score: 0.782071\n",
            "Epoch: 43, train_loss: 0.223391, val_loss: 0.440581, val_accuracy: 0.776198, best_score: 0.782071\n",
            "Epoch: 44, train_loss: 0.372986, val_loss: 0.415015, val_accuracy: 0.774034, best_score: 0.782071\n",
            "Epoch: 45, train_loss: 0.350131, val_loss: 0.461714, val_accuracy: 0.772798, best_score: 0.782071\n",
            "Epoch: 46, train_loss: 0.322049, val_loss: 0.431082, val_accuracy: 0.781762, best_score: 0.782071\n",
            "Epoch: 47, train_loss: 0.181437, val_loss: 0.451173, val_accuracy: 0.771870, best_score: 0.782071\n",
            "Epoch: 48, train_loss: 0.579194, val_loss: 0.451746, val_accuracy: 0.773725, best_score: 0.782071\n",
            "Epoch: 49, train_loss: 0.548527, val_loss: 0.417254, val_accuracy: 0.774652, best_score: 0.782071\n",
            "Epoch: 50, train_loss: 0.689662, val_loss: 0.441869, val_accuracy: 0.773107, best_score: 0.782071\n",
            "Epoch: 51, train_loss: 0.550362, val_loss: 0.455619, val_accuracy: 0.773725, best_score: 0.782071\n",
            "Epoch: 52, train_loss: 0.795276, val_loss: 0.470199, val_accuracy: 0.774034, best_score: 0.782071\n",
            "Epoch: 53, train_loss: 0.317591, val_loss: 0.437471, val_accuracy: 0.776198, best_score: 0.782071\n",
            "Epoch: 54, train_loss: 0.800590, val_loss: 0.466323, val_accuracy: 0.770943, best_score: 0.782071\n",
            "Epoch: 55, train_loss: 0.227438, val_loss: 0.448327, val_accuracy: 0.777125, best_score: 0.782071\n",
            "Epoch: 56, train_loss: 0.622148, val_loss: 0.467541, val_accuracy: 0.769397, best_score: 0.782071\n",
            "Epoch: 57, train_loss: 0.699684, val_loss: 0.476196, val_accuracy: 0.766306, best_score: 0.782071\n",
            "Epoch: 58, train_loss: 0.840851, val_loss: 0.443991, val_accuracy: 0.775889, best_score: 0.782071\n",
            "Epoch: 59, train_loss: 0.627205, val_loss: 0.453208, val_accuracy: 0.773725, best_score: 0.782071\n",
            "Epoch: 60, train_loss: 0.519852, val_loss: 0.426296, val_accuracy: 0.771870, best_score: 0.782071\n",
            "Epoch: 61, train_loss: 0.764677, val_loss: 0.418359, val_accuracy: 0.770325, best_score: 0.782071\n",
            "Epoch: 62, train_loss: 0.256806, val_loss: 0.416340, val_accuracy: 0.767543, best_score: 0.782071\n",
            "Epoch: 63, train_loss: 0.534276, val_loss: 0.439053, val_accuracy: 0.778362, best_score: 0.782071\n",
            "Epoch: 64, train_loss: 0.258210, val_loss: 0.445717, val_accuracy: 0.771252, best_score: 0.782071\n",
            "Epoch: 65, train_loss: 0.650571, val_loss: 0.457001, val_accuracy: 0.774034, best_score: 0.782071\n",
            "Epoch: 66, train_loss: 1.014028, val_loss: 0.468207, val_accuracy: 0.768779, best_score: 0.782071\n",
            "Epoch: 67, train_loss: 0.621221, val_loss: 0.446228, val_accuracy: 0.774652, best_score: 0.782071\n",
            "Epoch: 68, train_loss: 0.323333, val_loss: 0.427215, val_accuracy: 0.777743, best_score: 0.782071\n",
            "Epoch: 69, train_loss: 0.596956, val_loss: 0.481816, val_accuracy: 0.765070, best_score: 0.782071\n",
            "Epoch: 70, train_loss: 0.249198, val_loss: 0.461449, val_accuracy: 0.772798, best_score: 0.782071\n",
            "Epoch: 71, train_loss: 0.377234, val_loss: 0.433061, val_accuracy: 0.774343, best_score: 0.782071\n",
            "Epoch: 72, train_loss: 0.435876, val_loss: 0.447100, val_accuracy: 0.774034, best_score: 0.782071\n",
            "Epoch: 73, train_loss: 0.533436, val_loss: 0.428317, val_accuracy: 0.773725, best_score: 0.782071\n",
            "Epoch: 74, train_loss: 0.392331, val_loss: 0.420877, val_accuracy: 0.775580, best_score: 0.782071\n",
            "Epoch: 75, train_loss: 0.578950, val_loss: 0.436078, val_accuracy: 0.780835, best_score: 0.782071\n",
            "Epoch: 76, train_loss: 0.756120, val_loss: 0.444822, val_accuracy: 0.780526, best_score: 0.782071\n",
            "Epoch: 77, train_loss: 0.638302, val_loss: 0.417770, val_accuracy: 0.775270, best_score: 0.782071\n",
            "Epoch: 78, train_loss: 0.394622, val_loss: 0.446354, val_accuracy: 0.774961, best_score: 0.782071\n",
            "Epoch: 79, train_loss: 0.857405, val_loss: 0.443297, val_accuracy: 0.769088, best_score: 0.782071\n",
            "Epoch: 80, train_loss: 0.164450, val_loss: 0.438952, val_accuracy: 0.773416, best_score: 0.782071\n",
            "Epoch: 81, train_loss: 0.588696, val_loss: 0.419664, val_accuracy: 0.775580, best_score: 0.782071\n",
            "Epoch: 82, train_loss: 0.480826, val_loss: 0.448510, val_accuracy: 0.780526, best_score: 0.782071\n",
            "Epoch: 83, train_loss: 0.658560, val_loss: 0.413133, val_accuracy: 0.778671, best_score: 0.782071\n",
            "Epoch: 84, train_loss: 0.750752, val_loss: 0.445407, val_accuracy: 0.774343, best_score: 0.782071\n",
            "Epoch: 85, train_loss: 0.548140, val_loss: 0.434102, val_accuracy: 0.775270, best_score: 0.782071\n",
            "Epoch: 86, train_loss: 0.348449, val_loss: 0.436986, val_accuracy: 0.774961, best_score: 0.782071\n",
            "Epoch: 87, train_loss: 0.293794, val_loss: 0.458425, val_accuracy: 0.771561, best_score: 0.782071\n",
            "Epoch: 88, train_loss: 0.421149, val_loss: 0.423583, val_accuracy: 0.773725, best_score: 0.782071\n",
            "Epoch: 89, train_loss: 0.828811, val_loss: 0.431871, val_accuracy: 0.771870, best_score: 0.782071\n",
            "Epoch: 90, train_loss: 0.623160, val_loss: 0.436429, val_accuracy: 0.774343, best_score: 0.782071\n",
            "Epoch: 91, train_loss: 0.835266, val_loss: 0.412308, val_accuracy: 0.771252, best_score: 0.782071\n",
            "Epoch: 92, train_loss: 0.548249, val_loss: 0.446169, val_accuracy: 0.774961, best_score: 0.782071\n",
            "Epoch: 93, train_loss: 0.289159, val_loss: 0.416168, val_accuracy: 0.777125, best_score: 0.782071\n",
            "Epoch: 94, train_loss: 0.787720, val_loss: 0.420991, val_accuracy: 0.781762, best_score: 0.782071\n",
            "Epoch: 95, train_loss: 0.392735, val_loss: 0.462428, val_accuracy: 0.766306, best_score: 0.782071\n",
            "Epoch: 96, train_loss: 0.300436, val_loss: 0.435890, val_accuracy: 0.778980, best_score: 0.782071\n",
            "Epoch: 97, train_loss: 1.267233, val_loss: 0.407553, val_accuracy: 0.777125, best_score: 0.782071\n",
            "Epoch: 98, train_loss: 0.896063, val_loss: 0.397519, val_accuracy: 0.774034, best_score: 0.782071\n",
            "Epoch: 99, train_loss: 0.658894, val_loss: 0.497822, val_accuracy: 0.767233, best_score: 0.782071\n",
            "Epoch: 100, train_loss: 0.913955, val_loss: 0.435091, val_accuracy: 0.771561, best_score: 0.782071\n",
            "Epoch: 101, train_loss: 0.285458, val_loss: 0.423944, val_accuracy: 0.773107, best_score: 0.782071\n",
            "Epoch: 102, train_loss: 0.647694, val_loss: 0.419034, val_accuracy: 0.767233, best_score: 0.782071\n",
            "Epoch: 103, train_loss: 0.827848, val_loss: 0.410951, val_accuracy: 0.777743, best_score: 0.782071\n",
            "Epoch: 104, train_loss: 0.527067, val_loss: 0.411363, val_accuracy: 0.775270, best_score: 0.782071\n",
            "Epoch: 105, train_loss: 0.726570, val_loss: 0.410995, val_accuracy: 0.777434, best_score: 0.782071\n",
            "Epoch: 106, train_loss: 0.717673, val_loss: 0.420559, val_accuracy: 0.783617, best_score: 0.783617\n",
            "Epoch: 107, train_loss: 0.758807, val_loss: 0.403536, val_accuracy: 0.769397, best_score: 0.783617\n",
            "Epoch: 108, train_loss: 0.439417, val_loss: 0.402534, val_accuracy: 0.779598, best_score: 0.783617\n",
            "Epoch: 109, train_loss: 0.463225, val_loss: 0.425284, val_accuracy: 0.775889, best_score: 0.783617\n",
            "Epoch: 110, train_loss: 0.498981, val_loss: 0.445322, val_accuracy: 0.776816, best_score: 0.783617\n",
            "Epoch: 111, train_loss: 0.155648, val_loss: 0.430325, val_accuracy: 0.775270, best_score: 0.783617\n",
            "Epoch: 112, train_loss: 0.479357, val_loss: 0.406921, val_accuracy: 0.770634, best_score: 0.783617\n",
            "Epoch: 113, train_loss: 0.216243, val_loss: 0.403765, val_accuracy: 0.777743, best_score: 0.783617\n",
            "Epoch: 114, train_loss: 0.773598, val_loss: 0.436714, val_accuracy: 0.771561, best_score: 0.783617\n",
            "Epoch: 115, train_loss: 0.399525, val_loss: 0.441479, val_accuracy: 0.771561, best_score: 0.783617\n",
            "Epoch: 116, train_loss: 0.538819, val_loss: 0.467461, val_accuracy: 0.772798, best_score: 0.783617\n",
            "Epoch: 117, train_loss: 0.190902, val_loss: 0.452943, val_accuracy: 0.773725, best_score: 0.783617\n",
            "Epoch: 118, train_loss: 0.592415, val_loss: 0.408660, val_accuracy: 0.775889, best_score: 0.783617\n",
            "Epoch: 119, train_loss: 0.262818, val_loss: 0.477177, val_accuracy: 0.764142, best_score: 0.783617\n",
            "Epoch: 120, train_loss: 0.629357, val_loss: 0.442318, val_accuracy: 0.779289, best_score: 0.783617\n",
            "Epoch: 121, train_loss: 0.378065, val_loss: 0.457937, val_accuracy: 0.776198, best_score: 0.783617\n",
            "Epoch: 122, train_loss: 0.365057, val_loss: 0.444446, val_accuracy: 0.776507, best_score: 0.783617\n",
            "Epoch: 123, train_loss: 0.414382, val_loss: 0.445760, val_accuracy: 0.776198, best_score: 0.783617\n",
            "Epoch: 124, train_loss: 0.682569, val_loss: 0.430781, val_accuracy: 0.778053, best_score: 0.783617\n",
            "Epoch: 125, train_loss: 0.181267, val_loss: 0.413307, val_accuracy: 0.781762, best_score: 0.783617\n",
            "Epoch: 126, train_loss: 0.293001, val_loss: 0.444047, val_accuracy: 0.776816, best_score: 0.783617\n",
            "Epoch: 127, train_loss: 1.450925, val_loss: 0.466969, val_accuracy: 0.771252, best_score: 0.783617\n",
            "Epoch: 128, train_loss: 0.860602, val_loss: 0.411898, val_accuracy: 0.781453, best_score: 0.783617\n",
            "Epoch: 129, train_loss: 0.324095, val_loss: 0.431456, val_accuracy: 0.777434, best_score: 0.783617\n",
            "Epoch: 130, train_loss: 0.881581, val_loss: 0.423617, val_accuracy: 0.777434, best_score: 0.783617\n",
            "Epoch: 131, train_loss: 0.698927, val_loss: 0.444666, val_accuracy: 0.782689, best_score: 0.783617\n",
            "Epoch: 132, train_loss: 0.280000, val_loss: 0.452387, val_accuracy: 0.774652, best_score: 0.783617\n",
            "Epoch: 133, train_loss: 0.577383, val_loss: 0.420657, val_accuracy: 0.770634, best_score: 0.783617\n",
            "Epoch: 134, train_loss: 0.581829, val_loss: 0.406258, val_accuracy: 0.780835, best_score: 0.783617\n",
            "Epoch: 135, train_loss: 0.708516, val_loss: 0.410293, val_accuracy: 0.775580, best_score: 0.783617\n",
            "Epoch: 136, train_loss: 0.282380, val_loss: 0.402988, val_accuracy: 0.774652, best_score: 0.783617\n",
            "Epoch: 137, train_loss: 0.235699, val_loss: 0.387330, val_accuracy: 0.780216, best_score: 0.783617\n",
            "Epoch: 138, train_loss: 0.598654, val_loss: 0.418259, val_accuracy: 0.774343, best_score: 0.783617\n",
            "Epoch: 139, train_loss: 0.474715, val_loss: 0.431877, val_accuracy: 0.774034, best_score: 0.783617\n",
            "Epoch: 140, train_loss: 0.682163, val_loss: 0.408703, val_accuracy: 0.778671, best_score: 0.783617\n",
            "Epoch: 141, train_loss: 0.596640, val_loss: 0.398024, val_accuracy: 0.773416, best_score: 0.783617\n",
            "Epoch: 142, train_loss: 0.415535, val_loss: 0.452344, val_accuracy: 0.771561, best_score: 0.783617\n",
            "Epoch: 143, train_loss: 0.139279, val_loss: 0.415083, val_accuracy: 0.778980, best_score: 0.783617\n",
            "Epoch: 144, train_loss: 0.274770, val_loss: 0.423150, val_accuracy: 0.771252, best_score: 0.783617\n",
            "Epoch: 145, train_loss: 0.590407, val_loss: 0.420026, val_accuracy: 0.774034, best_score: 0.783617\n",
            "Epoch: 146, train_loss: 0.725156, val_loss: 0.418420, val_accuracy: 0.778053, best_score: 0.783617\n",
            "Epoch: 147, train_loss: 0.190552, val_loss: 0.419383, val_accuracy: 0.785471, best_score: 0.785471\n",
            "Epoch: 148, train_loss: 0.399924, val_loss: 0.422524, val_accuracy: 0.774343, best_score: 0.785471\n",
            "Epoch: 149, train_loss: 0.568897, val_loss: 0.432008, val_accuracy: 0.773107, best_score: 0.785471\n",
            "Epoch: 150, train_loss: 0.168364, val_loss: 0.412880, val_accuracy: 0.775580, best_score: 0.785471\n",
            "Epoch: 151, train_loss: 0.440382, val_loss: 0.440629, val_accuracy: 0.774652, best_score: 0.785471\n",
            "Epoch: 152, train_loss: 0.506193, val_loss: 0.443195, val_accuracy: 0.768779, best_score: 0.785471\n",
            "Epoch: 153, train_loss: 0.527597, val_loss: 0.453109, val_accuracy: 0.769088, best_score: 0.785471\n",
            "Epoch: 154, train_loss: 0.238649, val_loss: 0.455575, val_accuracy: 0.770015, best_score: 0.785471\n",
            "Epoch: 155, train_loss: 0.355226, val_loss: 0.440492, val_accuracy: 0.782998, best_score: 0.785471\n",
            "Epoch: 156, train_loss: 0.617486, val_loss: 0.443747, val_accuracy: 0.774961, best_score: 0.785471\n",
            "Epoch: 157, train_loss: 0.723115, val_loss: 0.403757, val_accuracy: 0.778362, best_score: 0.785471\n",
            "Epoch: 158, train_loss: 0.648944, val_loss: 0.416886, val_accuracy: 0.780526, best_score: 0.785471\n",
            "Epoch: 159, train_loss: 0.419572, val_loss: 0.461309, val_accuracy: 0.770634, best_score: 0.785471\n",
            "Epoch: 160, train_loss: 0.416844, val_loss: 0.470190, val_accuracy: 0.768779, best_score: 0.785471\n",
            "Epoch: 161, train_loss: 0.900499, val_loss: 0.439983, val_accuracy: 0.777743, best_score: 0.785471\n",
            "Epoch: 162, train_loss: 0.595945, val_loss: 0.425339, val_accuracy: 0.776198, best_score: 0.785471\n",
            "Epoch: 163, train_loss: 0.160379, val_loss: 0.483799, val_accuracy: 0.766615, best_score: 0.785471\n",
            "Epoch: 164, train_loss: 0.323993, val_loss: 0.498147, val_accuracy: 0.768161, best_score: 0.785471\n",
            "Epoch: 165, train_loss: 0.561852, val_loss: 0.496001, val_accuracy: 0.771561, best_score: 0.785471\n",
            "Epoch: 166, train_loss: 0.519126, val_loss: 0.438104, val_accuracy: 0.774652, best_score: 0.785471\n",
            "Epoch: 167, train_loss: 0.295205, val_loss: 0.461959, val_accuracy: 0.769706, best_score: 0.785471\n",
            "Epoch: 168, train_loss: 0.318069, val_loss: 0.451661, val_accuracy: 0.767543, best_score: 0.785471\n",
            "Epoch: 169, train_loss: 0.480231, val_loss: 0.442618, val_accuracy: 0.773107, best_score: 0.785471\n",
            "Epoch: 170, train_loss: 0.421605, val_loss: 0.450104, val_accuracy: 0.775270, best_score: 0.785471\n",
            "Epoch: 171, train_loss: 0.471081, val_loss: 0.419728, val_accuracy: 0.781453, best_score: 0.785471\n",
            "Epoch: 172, train_loss: 0.198437, val_loss: 0.443616, val_accuracy: 0.778053, best_score: 0.785471\n",
            "Epoch: 173, train_loss: 0.202802, val_loss: 0.423503, val_accuracy: 0.775889, best_score: 0.785471\n",
            "Epoch: 174, train_loss: 0.456618, val_loss: 0.432976, val_accuracy: 0.781762, best_score: 0.785471\n",
            "Epoch: 175, train_loss: 0.667694, val_loss: 0.454318, val_accuracy: 0.776198, best_score: 0.785471\n",
            "Epoch: 176, train_loss: 0.627043, val_loss: 0.423613, val_accuracy: 0.776816, best_score: 0.785471\n",
            "Epoch: 177, train_loss: 0.158011, val_loss: 0.451999, val_accuracy: 0.773725, best_score: 0.785471\n",
            "Epoch: 178, train_loss: 0.476804, val_loss: 0.430026, val_accuracy: 0.776198, best_score: 0.785471\n",
            "Epoch: 179, train_loss: 0.230861, val_loss: 0.427606, val_accuracy: 0.778671, best_score: 0.785471\n",
            "Epoch: 180, train_loss: 0.455046, val_loss: 0.400705, val_accuracy: 0.779907, best_score: 0.785471\n",
            "Epoch: 181, train_loss: 0.461855, val_loss: 0.413014, val_accuracy: 0.777125, best_score: 0.785471\n",
            "Epoch: 182, train_loss: 0.343830, val_loss: 0.419439, val_accuracy: 0.778980, best_score: 0.785471\n",
            "Epoch: 183, train_loss: 1.359683, val_loss: 0.430792, val_accuracy: 0.775889, best_score: 0.785471\n",
            "Epoch: 184, train_loss: 0.645368, val_loss: 0.433023, val_accuracy: 0.773725, best_score: 0.785471\n",
            "Epoch: 185, train_loss: 0.220626, val_loss: 0.428584, val_accuracy: 0.775270, best_score: 0.785471\n",
            "Epoch: 186, train_loss: 0.594298, val_loss: 0.405071, val_accuracy: 0.774652, best_score: 0.785471\n",
            "Epoch: 187, train_loss: 0.515418, val_loss: 0.442603, val_accuracy: 0.766924, best_score: 0.785471\n",
            "Epoch: 188, train_loss: 0.742598, val_loss: 0.372673, val_accuracy: 0.782689, best_score: 0.785471\n",
            "Epoch: 189, train_loss: 0.550691, val_loss: 0.386599, val_accuracy: 0.776507, best_score: 0.785471\n",
            "Epoch: 190, train_loss: 0.370087, val_loss: 0.437521, val_accuracy: 0.774034, best_score: 0.785471\n",
            "Epoch: 191, train_loss: 0.408629, val_loss: 0.444665, val_accuracy: 0.770015, best_score: 0.785471\n",
            "Epoch: 192, train_loss: 0.260798, val_loss: 0.429260, val_accuracy: 0.779289, best_score: 0.785471\n",
            "Epoch: 193, train_loss: 0.397403, val_loss: 0.431913, val_accuracy: 0.774961, best_score: 0.785471\n",
            "Epoch: 194, train_loss: 0.663179, val_loss: 0.459447, val_accuracy: 0.781762, best_score: 0.785471\n",
            "Epoch: 195, train_loss: 0.622490, val_loss: 0.446229, val_accuracy: 0.778053, best_score: 0.785471\n",
            "Epoch: 196, train_loss: 0.367888, val_loss: 0.417461, val_accuracy: 0.775580, best_score: 0.785471\n",
            "Epoch: 197, train_loss: 0.778452, val_loss: 0.382966, val_accuracy: 0.773725, best_score: 0.785471\n",
            "Epoch: 198, train_loss: 0.410813, val_loss: 0.424716, val_accuracy: 0.770634, best_score: 0.785471\n",
            "Epoch: 199, train_loss: 0.373003, val_loss: 0.421836, val_accuracy: 0.781762, best_score: 0.785471\n",
            "Epoch: 200, train_loss: 0.466157, val_loss: 0.450784, val_accuracy: 0.776816, best_score: 0.785471\n",
            "Epoch: 201, train_loss: 0.174818, val_loss: 0.440592, val_accuracy: 0.780216, best_score: 0.785471\n",
            "Epoch: 202, train_loss: 0.348301, val_loss: 0.453975, val_accuracy: 0.777434, best_score: 0.785471\n",
            "Epoch: 203, train_loss: 0.523702, val_loss: 0.402448, val_accuracy: 0.777125, best_score: 0.785471\n",
            "Epoch: 204, train_loss: 0.883781, val_loss: 0.434838, val_accuracy: 0.775580, best_score: 0.785471\n",
            "Epoch: 205, train_loss: 1.265404, val_loss: 0.432571, val_accuracy: 0.774034, best_score: 0.785471\n",
            "Epoch: 206, train_loss: 0.565435, val_loss: 0.404243, val_accuracy: 0.779907, best_score: 0.785471\n",
            "Epoch: 207, train_loss: 0.229055, val_loss: 0.420724, val_accuracy: 0.774961, best_score: 0.785471\n",
            "Epoch: 208, train_loss: 0.493901, val_loss: 0.403958, val_accuracy: 0.783308, best_score: 0.785471\n",
            "Epoch: 209, train_loss: 0.788596, val_loss: 0.409319, val_accuracy: 0.781762, best_score: 0.785471\n",
            "Epoch: 210, train_loss: 0.718288, val_loss: 0.502805, val_accuracy: 0.768779, best_score: 0.785471\n",
            "Epoch: 211, train_loss: 0.251447, val_loss: 0.443791, val_accuracy: 0.773725, best_score: 0.785471\n",
            "Epoch: 212, train_loss: 0.229906, val_loss: 0.439991, val_accuracy: 0.777743, best_score: 0.785471\n",
            "Epoch: 213, train_loss: 0.264691, val_loss: 0.440184, val_accuracy: 0.773416, best_score: 0.785471\n",
            "Epoch: 214, train_loss: 0.244726, val_loss: 0.424137, val_accuracy: 0.772488, best_score: 0.785471\n",
            "Epoch: 215, train_loss: 0.463116, val_loss: 0.461115, val_accuracy: 0.769706, best_score: 0.785471\n",
            "Epoch: 216, train_loss: 0.647511, val_loss: 0.449456, val_accuracy: 0.766924, best_score: 0.785471\n",
            "Epoch: 217, train_loss: 0.619759, val_loss: 0.447242, val_accuracy: 0.777125, best_score: 0.785471\n",
            "Epoch: 218, train_loss: 0.588194, val_loss: 0.460943, val_accuracy: 0.773107, best_score: 0.785471\n",
            "Epoch: 219, train_loss: 0.208812, val_loss: 0.428173, val_accuracy: 0.770325, best_score: 0.785471\n",
            "Epoch: 220, train_loss: 0.445009, val_loss: 0.400442, val_accuracy: 0.773725, best_score: 0.785471\n",
            "Epoch: 221, train_loss: 0.660190, val_loss: 0.425791, val_accuracy: 0.774961, best_score: 0.785471\n",
            "Epoch: 222, train_loss: 0.366867, val_loss: 0.427893, val_accuracy: 0.770015, best_score: 0.785471\n",
            "Epoch: 223, train_loss: 0.312213, val_loss: 0.438622, val_accuracy: 0.772179, best_score: 0.785471\n",
            "Epoch: 224, train_loss: 0.185978, val_loss: 0.424276, val_accuracy: 0.776816, best_score: 0.785471\n",
            "Epoch: 225, train_loss: 0.249666, val_loss: 0.439093, val_accuracy: 0.772488, best_score: 0.785471\n",
            "Epoch: 226, train_loss: 0.421086, val_loss: 0.440609, val_accuracy: 0.774652, best_score: 0.785471\n",
            "Epoch: 227, train_loss: 0.206882, val_loss: 0.445681, val_accuracy: 0.775889, best_score: 0.785471\n",
            "Epoch: 228, train_loss: 0.544892, val_loss: 0.402264, val_accuracy: 0.778362, best_score: 0.785471\n",
            "Epoch: 229, train_loss: 0.390754, val_loss: 0.413464, val_accuracy: 0.775889, best_score: 0.785471\n",
            "Epoch: 230, train_loss: 0.501922, val_loss: 0.417577, val_accuracy: 0.770943, best_score: 0.785471\n",
            "Epoch: 231, train_loss: 0.694211, val_loss: 0.427531, val_accuracy: 0.779289, best_score: 0.785471\n",
            "Epoch: 232, train_loss: 0.356796, val_loss: 0.425221, val_accuracy: 0.785471, best_score: 0.785471\n",
            "Epoch: 233, train_loss: 0.219574, val_loss: 0.445754, val_accuracy: 0.778053, best_score: 0.785471\n",
            "Epoch: 234, train_loss: 0.155807, val_loss: 0.456556, val_accuracy: 0.777125, best_score: 0.785471\n",
            "Epoch: 235, train_loss: 0.333113, val_loss: 0.436961, val_accuracy: 0.776816, best_score: 0.785471\n",
            "Epoch: 236, train_loss: 0.316223, val_loss: 0.458864, val_accuracy: 0.767233, best_score: 0.785471\n",
            "Epoch: 237, train_loss: 0.721710, val_loss: 0.444868, val_accuracy: 0.769706, best_score: 0.785471\n",
            "Epoch: 238, train_loss: 0.252461, val_loss: 0.449413, val_accuracy: 0.771252, best_score: 0.785471\n",
            "Epoch: 239, train_loss: 0.225091, val_loss: 0.440939, val_accuracy: 0.769088, best_score: 0.785471\n",
            "Epoch: 240, train_loss: 0.289735, val_loss: 0.416486, val_accuracy: 0.780835, best_score: 0.785471\n",
            "Epoch: 241, train_loss: 0.629217, val_loss: 0.501562, val_accuracy: 0.765997, best_score: 0.785471\n",
            "Epoch: 242, train_loss: 0.684583, val_loss: 0.449931, val_accuracy: 0.776198, best_score: 0.785471\n",
            "Epoch: 243, train_loss: 0.279415, val_loss: 0.426063, val_accuracy: 0.781453, best_score: 0.785471\n",
            "Epoch: 244, train_loss: 0.736554, val_loss: 0.379727, val_accuracy: 0.772488, best_score: 0.785471\n",
            "Epoch: 245, train_loss: 0.786461, val_loss: 0.383359, val_accuracy: 0.777434, best_score: 0.785471\n",
            "Epoch: 246, train_loss: 0.371758, val_loss: 0.462581, val_accuracy: 0.782071, best_score: 0.785471\n",
            "Epoch: 247, train_loss: 0.200396, val_loss: 0.429347, val_accuracy: 0.776198, best_score: 0.785471\n",
            "Epoch: 248, train_loss: 0.508834, val_loss: 0.426654, val_accuracy: 0.780526, best_score: 0.785471\n",
            "Epoch: 249, train_loss: 0.398261, val_loss: 0.433927, val_accuracy: 0.774034, best_score: 0.785471\n",
            "Epoch: 250, train_loss: 0.182976, val_loss: 0.403611, val_accuracy: 0.776507, best_score: 0.785471\n",
            "Epoch: 251, train_loss: 0.493564, val_loss: 0.457672, val_accuracy: 0.774961, best_score: 0.785471\n",
            "Epoch: 252, train_loss: 0.369928, val_loss: 0.440546, val_accuracy: 0.772179, best_score: 0.785471\n",
            "Epoch: 253, train_loss: 0.982158, val_loss: 0.457720, val_accuracy: 0.771561, best_score: 0.785471\n",
            "Epoch: 254, train_loss: 0.214328, val_loss: 0.425675, val_accuracy: 0.781144, best_score: 0.785471\n",
            "Epoch: 255, train_loss: 0.353340, val_loss: 0.427509, val_accuracy: 0.771870, best_score: 0.785471\n",
            "Epoch: 256, train_loss: 0.471093, val_loss: 0.434950, val_accuracy: 0.778053, best_score: 0.785471\n",
            "Epoch: 257, train_loss: 0.395385, val_loss: 0.409039, val_accuracy: 0.777434, best_score: 0.785471\n",
            "Epoch: 258, train_loss: 0.297585, val_loss: 0.411129, val_accuracy: 0.777743, best_score: 0.785471\n",
            "Epoch: 259, train_loss: 1.047485, val_loss: 0.370628, val_accuracy: 0.781762, best_score: 0.785471\n",
            "Epoch: 260, train_loss: 0.170241, val_loss: 0.441890, val_accuracy: 0.771870, best_score: 0.785471\n",
            "Epoch: 261, train_loss: 0.424436, val_loss: 0.416760, val_accuracy: 0.777743, best_score: 0.785471\n",
            "Epoch: 262, train_loss: 0.512777, val_loss: 0.423522, val_accuracy: 0.773725, best_score: 0.785471\n",
            "Epoch: 263, train_loss: 0.155464, val_loss: 0.445309, val_accuracy: 0.777125, best_score: 0.785471\n",
            "Epoch: 264, train_loss: 0.620110, val_loss: 0.448428, val_accuracy: 0.773725, best_score: 0.785471\n",
            "Epoch: 265, train_loss: 0.420008, val_loss: 0.469975, val_accuracy: 0.763215, best_score: 0.785471\n",
            "Epoch: 266, train_loss: 0.481411, val_loss: 0.419151, val_accuracy: 0.774343, best_score: 0.785471\n",
            "Epoch: 267, train_loss: 0.284489, val_loss: 0.443152, val_accuracy: 0.769397, best_score: 0.785471\n",
            "Epoch: 268, train_loss: 0.566406, val_loss: 0.421997, val_accuracy: 0.775270, best_score: 0.785471\n",
            "Epoch: 269, train_loss: 0.420256, val_loss: 0.424965, val_accuracy: 0.781453, best_score: 0.785471\n",
            "Epoch: 270, train_loss: 0.438469, val_loss: 0.437347, val_accuracy: 0.774961, best_score: 0.785471\n",
            "Epoch: 271, train_loss: 0.555457, val_loss: 0.428223, val_accuracy: 0.775580, best_score: 0.785471\n",
            "Epoch: 272, train_loss: 0.817316, val_loss: 0.452506, val_accuracy: 0.772179, best_score: 0.785471\n",
            "Epoch: 273, train_loss: 0.434024, val_loss: 0.458022, val_accuracy: 0.771252, best_score: 0.785471\n",
            "Epoch: 274, train_loss: 0.280464, val_loss: 0.443609, val_accuracy: 0.773107, best_score: 0.785471\n",
            "Epoch: 275, train_loss: 0.314620, val_loss: 0.430138, val_accuracy: 0.773725, best_score: 0.785471\n",
            "Epoch: 276, train_loss: 0.306861, val_loss: 0.464905, val_accuracy: 0.768470, best_score: 0.785471\n",
            "Epoch: 277, train_loss: 0.464076, val_loss: 0.473266, val_accuracy: 0.771561, best_score: 0.785471\n",
            "Epoch: 278, train_loss: 0.245680, val_loss: 0.437073, val_accuracy: 0.773725, best_score: 0.785471\n",
            "Epoch: 279, train_loss: 0.437797, val_loss: 0.432648, val_accuracy: 0.773725, best_score: 0.785471\n",
            "Epoch: 280, train_loss: 0.365077, val_loss: 0.434419, val_accuracy: 0.773725, best_score: 0.785471\n",
            "Epoch: 281, train_loss: 0.748897, val_loss: 0.444200, val_accuracy: 0.775270, best_score: 0.785471\n",
            "Epoch: 282, train_loss: 0.753663, val_loss: 0.460521, val_accuracy: 0.774034, best_score: 0.785471\n",
            "Epoch: 283, train_loss: 0.517718, val_loss: 0.443642, val_accuracy: 0.771870, best_score: 0.785471\n",
            "Epoch: 284, train_loss: 0.540410, val_loss: 0.424850, val_accuracy: 0.772488, best_score: 0.785471\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/oreomilkshake/HW/MachineLearning/FacialExpressionClassification/mariano_alex_assignment3.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/oreomilkshake/HW/MachineLearning/FacialExpressionClassification/mariano_alex_assignment3.ipynb#X41sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m total \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/oreomilkshake/HW/MachineLearning/FacialExpressionClassification/mariano_alex_assignment3.ipynb#X41sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/oreomilkshake/HW/MachineLearning/FacialExpressionClassification/mariano_alex_assignment3.ipynb#X41sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mfor\u001b[39;00m imgs, labels \u001b[39min\u001b[39;00m val_loader:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/oreomilkshake/HW/MachineLearning/FacialExpressionClassification/mariano_alex_assignment3.ipynb#X41sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m         imgs, labels \u001b[39m=\u001b[39m imgs\u001b[39m.\u001b[39mto(device), labels\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/oreomilkshake/HW/MachineLearning/FacialExpressionClassification/mariano_alex_assignment3.ipynb#X41sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         outputs \u001b[39m=\u001b[39m model(imgs)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1284\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m   1283\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_thread\u001b[39m.\u001b[39mis_alive():\n\u001b[0;32m-> 1284\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1285\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1286\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1133\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
            "File \u001b[0;32m/usr/lib/python3.8/queue.py:179\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[39mif\u001b[39;00m remaining \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[1;32m    178\u001b[0m             \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m--> 179\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait(remaining)\n\u001b[1;32m    180\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get()\n\u001b[1;32m    181\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnot_full\u001b[39m.\u001b[39mnotify()\n",
            "File \u001b[0;32m/usr/lib/python3.8/threading.py:306\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 306\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[1;32m    307\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "learning_rate = 1e-2\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "n_epochs = 1000\n",
        "best_score = 0\n",
        "#model.load_state_dict(torch.load('best-model2-paramteres.pt'))\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    model.train(True)\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        #print(labels)\n",
        "        \n",
        "        outputs = model(imgs)   # important:  nn.Conv2d expects a B  C  H  W shaped tensor as input\n",
        "        train_loss = loss_fn(outputs, labels)\n",
        "  \n",
        "        optimizer.zero_grad()\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            \n",
        "            outputs = model(imgs)\n",
        "            val_loss = loss_fn(outputs, labels)\n",
        "            \n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "            #print(predicted)\n",
        "            total += labels.shape[0]\n",
        "            correct += int((predicted == labels).sum())\n",
        "    val_accuracy = correct / total\n",
        "    if val_accuracy > best_score:\n",
        "        torch.save(model.state_dict(), 'best-model3-paramteres.pt')\n",
        "        best_score = val_accuracy\n",
        "    print(\"Epoch: %d, train_loss: %f, val_loss: %f, val_accuracy: %f, best_score: %f\" % (epoch, float(train_loss), float(val_loss), val_accuracy, best_score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3965, 2304)\n",
            "(3965, 2304)\n",
            "3965\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('best-model3-paramteres.pt'))\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "test_data = pd.read_csv('test_data.csv', header=None)\n",
        "test_data.to_csv('test_data2.csv')\n",
        "processed_test_data = test_data.to_numpy()\n",
        "print(test_data.shape)\n",
        "print(processed_test_data.shape)\n",
        "processed_test_dataset = CustomDataset(processed_test_data, train_target,\n",
        "    transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.4915, 0.2470)\n",
        "    ]))\n",
        "processed_test_data_loader = torch.utils.data.DataLoader(processed_test_dataset, batch_size=1, shuffle=False,  **kwargs)\n",
        "output_list = np.zeros(processed_test_dataset.__len__(), dtype=int)\n",
        "print(processed_test_dataset.__len__())\n",
        "iter = 0\n",
        "for test_img, labels in processed_test_data_loader:\n",
        "    test_img = test_img.to(device)\n",
        "    output = model(test_img)\n",
        "    _, predicted = torch.max(output, dim=1)\n",
        "    output_list[iter] = predicted\n",
        "    iter += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2 0 0 ... 1 2 0]\n"
          ]
        }
      ],
      "source": [
        "output_dataframe = pd.DataFrame(output_list)\n",
        "print(output_list)\n",
        "output_dataframe.to_csv('output2.csv', index=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
